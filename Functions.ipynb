{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Functions.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MHTpW-MY-AXF"},"source":["# Licenses"]},{"cell_type":"code","metadata":{"id":"k2QMetc6kava"},"source":["#@title ##### GraphNets License { form-width: \"50%\" }\n","# Copyright 2018 The GraphNets Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#    http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ============================================================================"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m4OzEg69BWT3"},"source":["#@title ##### Modified Notice - MCMB Lab { form-width: \"50%\" }\n","# The GraphNets framework has been modified by:\n","# Multiscale Computational Mechanics and Biomechanics LAB (MCMB Lab)\n","# Department of Mechanical Engineering and Mechanics\n","# Drexel University, Philadelphia, Pennsylvania \n","# Diroctor: Ahmad Raeisi Najafi (Ph.D.)\n","# All rights reserved.\n","# Developer: Nolan Black 10/2020\n","# Created in: 10/2020\n","# Last modified in: 2021\n","# ============================================================================"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e44hz9Fb2oOA"},"source":["\\\n","# Install Libraries On this Runtime\n","\n","\n","\\\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ss54UNGvkz5M","executionInfo":{"status":"ok","timestamp":1625352984819,"user_tz":240,"elapsed":61641,"user":{"displayName":"Nolan Black","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhprvLs3QsLT_d9iizVDA0ZEOiIS-hBEAdyKKDI=s64","userId":"18413703573618251084"}},"outputId":"1c685c83-d5ae-4765-8d99-6ddbd8607cba"},"source":["#@title ### Install the Graph Nets library on this Colaboratory runtime  { form-width: \"10%\", run: \"auto\"}\n","#@markdown <br>1. Connect to a local or hosted Colaboratory runtime by clicking the **Connect** button at the top-right.<br>2. Choose \"Yes\" below to install the Graph Nets library on the runtime machine with the correct dependencies. Note, this works both with local and hosted Colaboratory runtimes.\n","\n","install_graph_nets_library = \"Yes\"  #@param [\"Yes\", \"No\"]\n","\n","if install_graph_nets_library.lower() == \"yes\":\n","  print(\"Installing Graph Nets library and dependencies:\")\n","  print(\"Output message from command:\\n\")\n","  #!pip install graph_nets \"dm-sonnet<2\" \"tensorflow_probability<0.9\"\n","  !pip install graph_nets \"tensorflow_gpu>=1.15,<2\" \"dm-sonnet<2\" \"tensorflow_probability<0.9\"\n","else:\n","  print(\"Skipping installation of Graph Nets library\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Installing Graph Nets library and dependencies:\n","Output message from command:\n","\n","Collecting graph_nets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/7a/a4a686426b1eae92887280d008c92bac2a0d1ed7dfa083a277d64f47555f/graph_nets-1.1.0.tar.gz (76kB)\n","\u001b[K     |████████████████████████████████| 81kB 3.3MB/s \n","\u001b[?25hCollecting tensorflow_gpu<2,>=1.15\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/b5/adc281ce4e631251c749d342793795832026edf9035df81c3813ef33fad2/tensorflow_gpu-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (411.0MB)\n","\u001b[K     |████████████████████████████████| 411.0MB 42kB/s \n","\u001b[?25hCollecting dm-sonnet<2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/14/e221b910127bf4e2c19bc6d3b3e65a4e0104b90f7e98a3d428926474ece3/dm_sonnet-1.36-py3-none-any.whl (665kB)\n","\u001b[K     |████████████████████████████████| 665kB 21.9MB/s \n","\u001b[?25hCollecting tensorflow_probability<0.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/72/29ef1e5f386b65544d4e7002dfeca1e55b099ed182cd6d405c21a19ae259/tensorflow_probability-0.8.0-py2.py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 30.0MB/s \n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from graph_nets) (0.12.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from graph_nets) (0.1.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from graph_nets) (0.16.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from graph_nets) (2.5.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from graph_nets) (1.19.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from graph_nets) (57.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from graph_nets) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu<2,>=1.15) (1.1.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu<2,>=1.15) (3.12.4)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu<2,>=1.15) (0.8.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu<2,>=1.15) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu<2,>=1.15) (0.2.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu<2,>=1.15) (1.12.1)\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu<2,>=1.15) (1.34.1)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu<2,>=1.15) (3.3.0)\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 29.5MB/s \n","\u001b[?25hCollecting h5py<=2.10.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 33.3MB/s \n","\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 28.8MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu<2,>=1.15) (0.36.2)\n","Collecting semantic-version\n","  Downloading https://files.pythonhosted.org/packages/a5/15/00ef3b7888a10363b7c402350eda3acf395ff05bebae312d1296e528516a/semantic_version-2.8.5-py2.py3-none-any.whl\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet<2) (0.5.5)\n","Collecting cloudpickle==1.1.1\n","  Downloading https://files.pythonhosted.org/packages/24/fb/4f92f8c0f40a0d728b4f3d5ec5ff84353e705d8ff5e3e447620ea98b06bd/cloudpickle-1.1.1-py2.py3-none-any.whl\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability<0.9) (4.4.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu<2,>=1.15) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu<2,>=1.15) (1.0.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu<2,>=1.15) (4.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu<2,>=1.15) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu<2,>=1.15) (3.4.1)\n","Building wheels for collected packages: graph-nets, gast\n","  Building wheel for graph-nets (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for graph-nets: filename=graph_nets-1.1.0-cp37-none-any.whl size=91856 sha256=a845025aebe0c9c015436b1209db618d593b9a684929df0c7dbfd868d0704785\n","  Stored in directory: /root/.cache/pip/wheels/c9/85/dc/ad3c616f83f0774ff12d6d7599850f56d82976e8590e59e864\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7557 sha256=832f87d2683908d9333d8f5352316cffba5b0cc0900d0a3643277d9d699d66eb\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built graph-nets gast\n","\u001b[31mERROR: tensorflow 2.5.0 has requirement gast==0.4.0, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorboard~=2.5, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorflow-estimator<2.6.0,>=2.5.0rc0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: gym 0.17.3 has requirement cloudpickle<1.7.0,>=1.2.0, but you'll have cloudpickle 1.1.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-gpu 1.15.5 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n","Installing collected packages: gast, cloudpickle, tensorflow-probability, semantic-version, dm-sonnet, graph-nets, h5py, keras-applications, tensorflow-estimator, tensorboard, tensorflow-gpu\n","  Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","  Found existing installation: tensorflow-probability 0.12.1\n","    Uninstalling tensorflow-probability-0.12.1:\n","      Successfully uninstalled tensorflow-probability-0.12.1\n","  Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Found existing installation: tensorflow-estimator 2.5.0\n","    Uninstalling tensorflow-estimator-2.5.0:\n","      Successfully uninstalled tensorflow-estimator-2.5.0\n","  Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","Successfully installed cloudpickle-1.1.1 dm-sonnet-1.36 gast-0.2.2 graph-nets-1.1.0 h5py-2.10.0 keras-applications-1.0.8 semantic-version-2.8.5 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.5 tensorflow-probability-0.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R91Q2OiSV6Kd","executionInfo":{"status":"ok","timestamp":1625352988759,"user_tz":240,"elapsed":3946,"user":{"displayName":"Nolan Black","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhprvLs3QsLT_d9iizVDA0ZEOiIS-hBEAdyKKDI=s64","userId":"18413703573618251084"}},"outputId":"fd5a62be-78e4-48e2-c1b6-b61451c8511d"},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import time\n","\n","from graph_nets import blocks\n","from graph_nets import utils_tf\n","from graph_nets import utils_np\n","from graph_nets import graphs\n","#from graph_nets.demos import models\n","from matplotlib import pyplot as plt\n","import matplotlib as mpl\n","import numpy as np\n","import sonnet as snt\n","import tensorflow as tf\n","import scipy\n","import scipy.stats as stats\n","import dill\n","# Optimization Params\n","from scipy.sparse import diags\n","from scipy.sparse.linalg import spsolve as sparse_solve\n","# from scipy.linalg import solve \n","from numpy.linalg import solve\n","import warnings\n","import copy\n","\n","try:\n","  import seaborn as sns\n","except ImportError:\n","  pass\n","else:\n","  sns.reset_orig()\n","\n","SEED = 1\n","np.random.seed(SEED)\n","tf.set_random_seed(SEED)\n","precision_base = 16 # to ease floating-point pains\n","\n","print(f\"Tensor Flow Version: {tf.__version__}\")\n","gpu = tf.test.is_gpu_available(\n","    cuda_only=False, min_cuda_compute_capability=None)\n","print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\n","\n","from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tensor Flow Version: 1.15.5\n","GPU is NOT AVAILABLE\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 14522338480000962145, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 11285393118811749789\n"," physical_device_desc: \"device: XLA_CPU device\"]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"IuRTHVdvjS6b"},"source":["# **FEA Functions**\n","3 Node triangular element\\\n","2nd order Gauss Quadrature Isoparametric mapping\\\n","Homogeneous, Isotropic Plane Stress (2D)\\\n","\n","4 Node quadrilateral element\\\n","2nd order Gauss Quadrature Isoparametric mapping\\\n","Homogeneous, Isotropic Plane Stress (2D)\\\n","aka CPS4, bilinear 2D Quad. Plane Stress\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0fpkxmjRvq8d"},"source":["### Helper Structures"]},{"cell_type":"code","metadata":{"id":"KXE0--rDL15D"},"source":["class Mesh() :\n","  def __init__(self, dim, m1, m2, d1, d2, bound_x, bound_y, nodes_per_elem, n_elem, n_node, coords, elem_nodes) :\n","    self.dim = dim # dimension, scalar\n","    self.m1 = m1 # elements in x, scalar\n","    self.m2 = m2 # elements in y, scalar   \n","    self.d1 = d1 # element x width, float\n","    self.d2 = d2 # element y width, float\n","    self.bound_x = bound_x # [-x_lim, +x_lim]\n","    self.bound_y = bound_y # [-y_lim, +y_lim]\n","    self.nodes_per_elem = nodes_per_elem # scalar\n","    self.n_elem = n_elem # scalar\n","    self.n_node = n_node # scalar\n","    self.coords = coords # [ [x_i, y_i], ...] for n_node\n","    self.elem_nodes = elem_nodes # [ [n0, n1, n2, n3] .... ] for n_elem\n","\n","\n","class Material() :\n","  def __init__(self, E, v, elem_stiff, elem_density, Ce) :\n","    self.E = E # scalar\n","    self.v = v # scalar\n","    self.elem_stiff = elem_stiff # [ [E_i, v_i] ...] for n_elem\n","    self.elem_density = elem_density # [ p_i, ... ] for n_elem\n","    self.Ce = Ce # [ [Cmat], ...] for n_elem\n","\n","class BC() :\n","  def __init__(self, n_pre_disp, n_dof, eq_num,  \n","               disp_dof, disp_node, disp_val,  \n","               force_dof, force_node, force_val, elem_load) :\n","    self.n_pre_disp = n_pre_disp # number of prescribed displacements\n","    self.n_dof = n_dof # number of free nodes\n","    self.eq_num = eq_num # list, defines free and prescribed nodes for matrix assembly\n","    self.disp_dof = disp_dof # [0, 1]\n","    self.disp_node = disp_node # node_id of prescribed disps\n","    self.disp_val = disp_val # presctibed disp value at each node_d\n","    self.force_dof = force_dof # force_dof at applied force nodes\n","    self.force_node = force_node # node_id of applied forces\n","    self.force_val = force_val # force val at each node_id\n","    self.elem_load = elem_load # [ [b_x, b_y] ... ] for n_elem, body force values\n","\n","class FEA() :\n","  def __init__(self, UP, PF, PP, KPP, KPF, KFP, KFF, KUR) :\n","    self.UP = UP\n","    self.PF = PF\n","    self.PP = PP\n","    self.KPP = KPP\n","    self.KPF = KPF\n","    self.KFP = KFP\n","    self.KFF = KFF\n","    self.KUR = KUR\n","\n","\n","class Results() :\n","  def __init__(self, UF, R, UUR, PUR) :\n","    self.UF = UF\n","    self.R = R\n","    self.UUR = UUR\n","    self.PUR = PUR"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"08oT7W0MvuPP"},"source":["### Mesh Noise"]},{"cell_type":"code","metadata":{"id":"WmkT3okqAFD5"},"source":["def refine_mesh(refine_fract, coords, n_node, elem_nodes, n_elem) :\n","  \"\"\"\n","  Refine a fraction of the existing elements to half their size. \n","  TRIANGULAR ELEM ONLY.\n","  Returns Refined: coords, n_node, elem_node, n_elem\n","  \"\"\"\n","  refined_coords = []\n","  already_refined = []\n","  \n","  num_refinements = int(refine_fract * n_elem / 2 ) \n","  for i in range(num_refinements) :\n","    refine_elem = 2 * (np.random.randint(0, n_elem-1) // 2)\n","    while (True) :\n","      if (refine_elem not in already_refined ) :\n","        break\n","      else :\n","        refine_elem = 2 * (np.random.randint(0, n_elem) // 2)\n","\n","    if i > 0 :\n","      for j, val in enumerate(already_refined) :\n","        if val > refine_elem :\n","            already_refined[j] += 2\n","        \n","    for j in range(4) :\n","      already_refined.append(refine_elem + j)\n","\n","\n","    elem_0 = elem_nodes[refine_elem]\n","    elem_1 = elem_nodes[refine_elem + 1]\n","    n_point = n_node\n","    \n","    n_x = (coords[elem_0[0]][0] + coords[elem_0[1]][0]) / 2\n","    n_y = (coords[elem_0[0]][1] + coords[elem_0[2]][1]) / 2\n","    coords.append([n_x, n_y])\n","    refined_coords.append([n_x, n_y])\n","    n_node +=1 \n","\n","    elem_nodes.pop(refine_elem)\n","    elem_nodes.pop(refine_elem)\n","    if elem_0[1] == elem_0[0] + 1 :\n","      elem_nodes.insert(refine_elem, [n_point, elem_1[1], elem_1[2]])\n","      elem_nodes.insert(refine_elem, [n_point, elem_0[1], elem_1[1]])\n","      elem_nodes.insert(refine_elem, [elem_0[0], elem_0[1], n_point])\n","      elem_nodes.insert(refine_elem, [elem_0[0], n_point, elem_0[2]])\n","    else :\n","      elem_nodes.insert(refine_elem, [n_point, elem_0[1], elem_0[2]])\n","      elem_nodes.insert(refine_elem, [n_point, elem_1[1], elem_1[2]])\n","      elem_nodes.insert(refine_elem, [elem_1[0], elem_1[1], n_point])\n","      elem_nodes.insert(refine_elem, [elem_0[0], n_point, elem_0[2]])\n","    n_elem +=2\n","\n","  return refined_coords, coords, n_node, elem_nodes, n_elem\n","\n","def noise_mesh(elem_type, noise_type, noise_coord_scale,\n","              refined_coords, coords, m1, m2, d1, d2) :\n","  \"\"\"\n","  Applies noise to the nodal positions.\n","  \"posi\" applies random uniform noise to the nodal posiions, \n","    within a certain neighborhood defined by noise_coord_scale\n","  \"row\" does all \"posi\" noise and also squeezes a row/column pair\n","    to crudely change element size.\n","  \n","  Returns: Noisy coordinates in coords. \n","  \"\"\"\n","\n","  \n","  if noise_type == \"posi\" :\n","    # Noise\n","    for i, point in enumerate(coords) :\n","      x, y = point[0], point[1]\n","      if [x, y] in refined_coords :\n","        if (x not in bound_x)  :\n","          x+= 0.5*noise_coord_scale*np.random.uniform(-d1, d1)\n","        if (y not in bound_y)  :\n","          y+= 0.5*noise_coord_scale*np.random.uniform(-d2, d2)\n","      else :\n","        if (x not in bound_x)  :\n","          x+= noise_coord_scale*np.random.uniform(-d1, d1)\n","        if (y not in bound_y)  :\n","          y+= noise_coord_scale*np.random.uniform(-d2, d2)\n","      coords[i] = [x, y]\n","  \n","  elif noise_type == \"row\" :\n","    # Shift mesh\n","    target_row = np.random.randint(2,m2-2)\n","    target_col = np.random.randint(2,m1-2)\n","    \n","    shifted_x = []\n","    shifted_y = []\n","    for j in range(-1,2,2) :\n","      fact = (-j//2)\n","      if j < 0 :\n","          fact +=1\n","      for i in range(m2 + 1) :\n","        node = i*(m1 + 1) + target_col -fact\n","        coords[node][0] += fact*d1*.5\n","        shifted_x.append(coords[node][0])\n","      start = (target_row-fact)*(m1 + 1)\n","      end = start + m1  +1\n","      for node in range(start, end) :\n","        coords[node][1] += fact*d2*.5\n","        shifted_y.append(coords[node][1])\n","    \n","    # Noise\n","    for i, point in enumerate(coords) :\n","      x, y = point[0], point[1]\n","      if (x not in bound_x) and (x not in shifted_x) :\n","        x+= noise_coord_scale*np.random.uniform(-d1, d1)\n","      elif (x not in bound_x) and (x in shifted_x):\n","        x+= 0.1*noise_coord_scale*np.random.uniform(-d1, d1)\n","      if (y not in bound_y) and (y not in shifted_y) :\n","        y+= noise_coord_scale*np.random.uniform(-d2, d2)\n","      elif (y not in bound_y) and (y in shifted_y):\n","        y+= 0.1*noise_coord_scale*np.random.uniform(-d2, d2)\n","      coords[i] = [x, y]\n","\n","  return coords\n","\n","def flat_list(list_of_lists) :\n","  return [item for sublist in list_of_lists for item in sublist]\n","\n","def noise_mesh_MS(noise_type, noise_coord_scale, mesh_0, mesh_1) :\n","  \"\"\"\n","  Applies noise to the nodal positions.\n","  \"posi\" applies random uniform noise to the nodal posiions, \n","    within a certain neighborhood defined by noise_coord_scale\n","  \"row\" does all \"posi\" noise and also squeezes a row/column pair\n","    to crudely change element size.\n","\n","  Does not change coords of the coarse mesh (mesh_0).\n","  ONLY affects fine mesh (mesh_1)\n","  \n","  Returns: Noisy coordinates in coords. \n","  \"\"\"\n","  coord_precision = 7\n","  coords = copy.deepcopy(mesh_1.coords)\n","  off_limit_x = [round(point[0], coord_precision) for point in mesh_0.coords] + list(mesh_0.bound_x)\n","  off_limit_y = [round(point[1], coord_precision) for point in mesh_0.coords] + list(mesh_0.bound_y)\n","\n","  if noise_type == \"posi\" :\n","    # Noise\n","    for i, point in enumerate(mesh_1.coords) :\n","      x, y = round(point[0], coord_precision), round(point[1], coord_precision)\n","      if (x not in off_limit_x) and (y not in off_limit_y) :\n","        x+= 1.0*noise_coord_scale*np.random.uniform(-mesh_1.d1, mesh_1.d1)\n","        y+= 1.0*noise_coord_scale*np.random.uniform(-mesh_1.d2, mesh_1.d2)\n","      mesh_1.coords[i] = [x, y]\n","  \n","  if noise_type == \"row\" :\n","    # Shift mesh\n","    m1_fact = mesh_1.m1 / mesh_0.m1\n","    m2_fact = mesh_1.m2 / mesh_0.m2\n","    # off_limits_m1 = []\n","    # for i in range(0, mesh_1.m1, m1_fact) :\n","    #   off_limits_m1\n","\n","    target_row = np.random.randint(2,mesh_1.m2-2)\n","    target_col = np.random.randint(2,mesh_1.m1-2)\n","    off_limit_range_m1 = [target_col + 1, target_col,  target_col -1]\n","    off_limit_range_m2 = [target_row + 1, target_row, target_row -1]\n","    while any([(val) % m2_fact == 0 for val in off_limit_range_m2]):\n","      target_row = np.random.randint(2,mesh_1.m2-2)\n","      off_limit_range_m2 = [target_row + 1, target_row, target_row -1]\n","    while any([(val) % m1_fact ==0 for val in off_limit_range_m1]) :\n","      target_col = np.random.randint(2,mesh_1.m1-2)\n","      off_limit_range_m1 = [target_col + 1, target_col,  target_col -1]\n","    \n","    shifted_x = []\n","    shifted_y = []\n","    for j in range(-1,2,2) :\n","      fact = (-j//2)\n","      if j < 0 :\n","          fact +=1\n","      for i in range(mesh_1.m2 + 1) :\n","        node = i*(mesh_1.m1 + 1) + target_col -fact\n","        mesh_1.coords[node][0] += fact*mesh_1.d1*.5\n","        shifted_x.append(mesh_1.coords[node][0])\n","      start = (target_row-fact)*(mesh_1.m1 + 1)\n","      end = start + mesh_1.m1  +1\n","      for node in range(start, end) :\n","        mesh_1.coords[node][1] += fact*mesh_1.d2*.5\n","        shifted_y.append(mesh_1.coords[node][1])\n","\n","    # Coord Noise\n","    for i, point in enumerate(mesh_1.coords) :\n","      x, y = round(point[0], coord_precision), round(point[1], coord_precision)\n","      if (x not in off_limit_x) :\n","        if x in shifted_x :\n","          x+= 0.0*noise_coord_scale*np.random.uniform(-mesh_1.d1, mesh_1.d1)\n","        else :\n","          x+= 1.0*noise_coord_scale*np.random.uniform(-mesh_1.d1, mesh_1.d1)\n","      if (y not in off_limit_y) :\n","        if y in shifted_y :\n","          y+= 0.0*noise_coord_scale*np.random.uniform(-mesh_1.d2, mesh_1.d2)\n","        else :\n","          y+= 1.0*noise_coord_scale*np.random.uniform(-mesh_1.d2, mesh_1.d2)\n","      mesh_1.coords[i] = [x, y]\n","\n","  return mesh_1.coords"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"98Azzfr5vvvA"},"source":["### FEA and Gauss Integration"]},{"cell_type":"code","metadata":{"id":"HVWk3ofYReaI"},"source":["def shape_funct(elem_type, r) :\n","  if elem_type == \"tri\" :\n","    N = [1 - r[0] - r[1], r[0], r[1]]\n","    DN = [[-1, -1], [1, 0], [0, 1]]\n","    return np.array(N), np.array(DN) \n","  else :\n","    N = [(1 - r[0])*(1 - r[1]),\n","            (1 + r[0])*(1 - r[1]),\n","            (1 + r[0])*(1 + r[1]),\n","            (1 - r[0])*(1 + r[1])]\n","    DN = [[-(1-r[1]), -(1-r[0])],\n","              [(1-r[1]), -(1+r[0])], \n","              [(1+r[1]), (1+r[0])], \n","              [-(1+r[1]), (1-r[0])]]\n","\n","    return 0.25 * np.array(N),  0.25 * np.array(DN)         \n","\n","def GaussQuad(elem_type) :\n","  \"\"\"\n","  2nd order gauss quadrature for FEA calculations.\n","  4 Node quadraleteral uses 4 interior integration points.\n","  3 Node triangular uses 3 vertices as integration points.\n","  Returns: points and weights for summation.\n","  \"\"\"\n","  if elem_type == \"tri\" :\n","    r = [[1/6, 1/6],\n","        [2/3, 1/6],\n","        [1/6, 2/3]]\n","    w = 1/3 + np.zeros((1,3))\n","  else :\n","    r = [[-1/np.math.sqrt(3), -1/np.math.sqrt(3)],\n","        [1/np.math.sqrt(3), -1/np.math.sqrt(3)],\n","        [1/np.math.sqrt(3),  1/np.math.sqrt(3)],\n","        [-1/np.math.sqrt(3),  1/np.math.sqrt(3)]]\n","    w = 1+ np.zeros((1,4))\n","\n","  return np.array(r), w\n","\n","def element(elem_type, elem_iter, mesh, material, bc) :\n","  \"\"\" \n","  Applies shape functions and Gauss Quadrature\n","  Returns: Element stiffness matrix, element force matrix\n","  \"\"\"\n","  r,w = GaussQuad(elem_type)\n","  \n","  if elem_type == \"tri\" :\n","    K_el = np.zeros((6,6))\n","    P_el = np.zeros((6,))\n","    x_el = [mesh.coords[mesh.elem_nodes[elem_iter][0]],\n","            mesh.coords[mesh.elem_nodes[elem_iter][1]],\n","            mesh.coords[mesh.elem_nodes[elem_iter][2]]]\n","    x_el = np.transpose(np.array(x_el))\n","    b = np.transpose(np.array(bc.elem_load[0:2,elem_iter]))\n","\n","    for i in range(r.size//2) :\n","      N, DN = shape_funct(elem_type, r[i])\n","      J = np.matmul(x_el, DN)\n","      detJ = J[0,0]*J[1,1] - J[0,1]*J[1,0]\n","      invJ = np.matrix([[J[1,1], -J[0,1]], [-J[1,0], J[0,0]]])/detJ\n","      B = np.matmul(DN, invJ)\n","      NhatToI = np.kron(np.transpose(N), np.eye(2))\n","      BhatToI = np.zeros((3,6))\n","      BhatToI[0,0] = B[0][0,0]\n","      BhatToI[1,1] = B[0][0,1]\n","      BhatToI[0,2] = B[1][0,0]\n","      BhatToI[1,3] = B[1][0,1]\n","      BhatToI[0,4] = B[2][0,0]\n","      BhatToI[1,5] = B[2][0,1]\n","      \n","      BhatToI[2,0] = BhatToI[1,1]\n","      BhatToI[2,1] = BhatToI[0,0]\n","      BhatToI[2,2] = BhatToI[1,3]\n","      BhatToI[2,3] = BhatToI[0,2]\n","      BhatToI[2,4] = BhatToI[1,5]\n","      BhatToI[2,5] = BhatToI[0,4]\n","\n","      K_el += 0.5*np.matmul(np.transpose(BhatToI),\n","                        np.matmul(material.Ce[elem_iter], BhatToI)) * detJ * w[0,i]\n","      P_el += np.matmul(np.transpose(NhatToI), b) * detJ * w[0,i]\n","\n","\n","  else :\n","    K_el = np.zeros((8,8))\n","    P_el = np.zeros((8,))\n","    x_el = [mesh.coords[mesh.elem_nodes[elem_iter][0]],\n","            mesh.coords[mesh.elem_nodes[elem_iter][1]],\n","            mesh.coords[mesh.elem_nodes[elem_iter][2]],\n","            mesh.coords[mesh.elem_nodes[elem_iter][3]]]\n","    x_el = np.transpose(np.array(x_el))\n","    b = np.transpose(np.array(bc.elem_load[0:2,elem_iter]))\n","\n","    for i in range(r.size//2) :\n","      N, DN = shape_funct(elem_type, r[i])\n","      J = np.matmul(x_el, DN)\n","      detJ = J[0,0]*J[1,1] - J[0,1]*J[1,0]\n","      B = np.matmul(DN, np.matrix([[J[1,1], -J[0,1]], [-J[1,0], J[0,0]]])/detJ)\n","      NhatToI = np.kron(np.transpose(N), np.eye(2))\n","      BhatToI = np.kron(np.transpose(B), np.eye(2))\n","      K_el += np.matmul(np.transpose(BhatToI),\n","                        np.matmul(material.Ce[elem_iter], BhatToI)) * detJ * w[0,i]\n","      P_el += np.matmul(np.transpose(NhatToI), b) * detJ * w[0,i]\n","    \n","  return K_el, P_el\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cA0lS9C8M0OX","colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"status":"error","timestamp":1645545731732,"user_tz":300,"elapsed":1368,"user":{"displayName":"Nolan Black","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhprvLs3QsLT_d9iizVDA0ZEOiIS-hBEAdyKKDI=s64","userId":"18413703573618251084"}},"outputId":"7929b15a-6943-4cc3-b512-7f4e69c643dd"},"source":["def assign_supports(support_option, mesh) :\n","  \n","  coord_precision = 5\n","\n","  if support_option == \"left_cantilever\" :\n","    n_pre_disp = 0\n","    disp_node = []\n","    for i, point in enumerate(mesh.coords) :\n","      if round(point[0],coord_precision) == mesh.bound_x[0] :\n","        for j in range(mesh.dim) :\n","          disp_node.append(i)\n","          n_pre_disp += 1\n","  \n","  if support_option == \"right_cantilever\" :\n","    n_pre_disp = 0\n","    disp_node = []\n","    for i, point in enumerate(mesh.coords) :\n","      if round(point[0],coord_precision) == mesh.bound_x[1] :\n","        for j in range(mesh.dim) :\n","          disp_node.append(i)\n","          n_pre_disp += 1\n","  \n","  if support_option == \"dual_cantilever\" :\n","    n_pre_disp = 0\n","    disp_node = []\n","    for i, point in enumerate(mesh.coords) :\n","      if round(point[0],coord_precision) == mesh.bound_x[0] or round(point[0], coord_precision) == mesh.bound_x[1] :\n","        for j in range(mesh.dim) :\n","          disp_node.append(i)\n","          n_pre_disp += 1\n","\n","  if support_option == \"MBB\" :\n","    n_pre_disp = 0\n","    disp_node = []\n","    for i, point in enumerate(mesh.coords) :\n","      if round(point[1], coord_precision) == mesh.bound_y[0] and ( round(point[0], coord_precision)  == mesh.bound_x[0] or round(point[0], coord_precision)  == mesh.bound_x[1] ):\n","        for j in range(mesh.dim) :\n","          disp_node.append(i)\n","          n_pre_disp += 1\n","  \n","  if support_option == \"L_bracket\" :\n","    n_pre_disp = 0\n","    disp_node = []\n","    for i, point in enumerate(mesh.coords) :\n","      if round(point[1], coord_precision) == (mesh.d2*(mesh.m1 + mesh.m2) + mesh.bound_y[0]) :\n","        for j in range(mesh.dim) :\n","          disp_node.append(i)\n","          n_pre_disp += 1\n","\n","  disp_dof = []\n","  disp_val = []\n","\n","  if support_option == \"left_slider\" or support_option == \"right_slider\" or support_option == \"shear_slider\" or support_option == \"twist_slider\":\n","    disp_node = []\n","    n_pre_disp = 0\n","    m1, m2 = mesh.m1, mesh.m2\n","    if support_option == \"left_slider\" :\n","      prescribed_disp_x = -0.2\n","      prescribed_disp_y = 0.0\n","    elif support_option == \"right_slider\" :\n","      prescribed_disp_x = 0.2\n","      prescribed_disp_y = 0.0\n","    elif support_option == \"shear_slider\" :\n","      prescribed_disp_x = 0.0\n","      prescribed_disp_y = 0.2\n","    else :\n","      prescribed_disp_x = 0.2\n","      prescribed_disp_y = 0.2\n","    # at left border\n","    start = 0\n","    increment = m1 + 1\n","    end = start + increment*(m2+1)\n","    for i in range(start, end, increment) :\n","      # prescribe x\n","      disp_node.append(i)\n","      disp_dof.append(0)\n","      disp_val.append(-prescribed_disp_x/2)\n","      n_pre_disp += 1\n","      # constrain y\n","      disp_node.append(i)\n","      disp_dof.append(1)\n","      disp_val.append(-prescribed_disp_y/2)\n","      n_pre_disp += 1\n","\n","    # at right  border\n","    start = m1\n","    increment = m1 + 1\n","    end = start + increment*(m2+1)\n","    for i in range(start, end, increment) :\n","      # prescribe x\n","      disp_node.append(i)\n","      disp_dof.append(0)\n","      disp_val.append(prescribed_disp_x/2)\n","      n_pre_disp += 1\n","      # constrain y\n","      disp_node.append(i)\n","      disp_dof.append(1)\n","      disp_val.append(prescribed_disp_y/2)\n","      n_pre_disp += 1\n","  else :\n","    for i in range(0, n_pre_disp, mesh.dim) :\n","      disp_dof.append(0)\n","      disp_dof.append(1)\n","      disp_val.append(0)\n","      disp_val.append(0)\n","  return n_pre_disp, disp_node, disp_dof, disp_val\n","\n","def assign_force(support_option, force_option, mesh, applied_force_dofs, applied_force_vals) :\n","\n","  force_dof = []\n","  force_node = []\n","  force_val = []\n","\n","  if support_option == \"left_cantilever\" or support_option == \"L_bracket\":\n","    node_shift = mesh.m1\n","  elif support_option == \"MBB\" :\n","    node_shift = np.random.choice([0, mesh.m1])\n","  else :\n","    node_shift = 0\n","\n","  if force_option == \"side_bottom\" :\n","    n_force = 6\n","    for i in range(int(n_force/2)) :\n","      fnode = int(node_shift + (mesh.m1 + 1)*(i+1))\n","      for j in range(mesh.dim) :\n","        force_dof.append(applied_force_dofs[j])\n","        force_val.append(applied_force_vals[j])\n","        force_node.append(fnode)\n","    for i in range(len(force_val)) :\n","      force_val[i] /= (n_force/2) \n","\n","  if force_option == \"side_top\" :\n","    n_force = 6\n","    for i in range(int(n_force/2)) :\n","      fnode = int(node_shift+ (mesh.m2-3 + i)*(mesh.m1 + 1))\n","      for j in range(mesh.dim) :\n","        force_dof.append(applied_force_dofs[j])\n","        force_val.append(applied_force_vals[j])\n","        force_node.append(fnode)\n","    for i in range(len(force_val)) :\n","      force_val[i] /= (n_force/2) \n","\n","  if force_option == \"side_center\" :\n","    n_force = 6\n","    for i in range(3) :\n","      fnode = int(node_shift + (mesh.m1 + 1)*(mesh.m2/2 - 1 + i))\n","      for j in range(mesh.dim) :\n","        force_dof.append(applied_force_dofs[j])\n","        force_val.append(applied_force_vals[j])\n","        force_node.append(fnode)\n","    for i in range(len(force_val)) :\n","      force_val[i] /= 3    \n","\n","  if force_option == \"top_center\" :\n","    n_force = 6\n","    for i in range(3) :\n","      fnode = int( (mesh.m1+1)*(mesh.m2+1) - mesh.m1/2 - 2 + i)\n","      for j in range(mesh.dim) :\n","        force_dof.append(applied_force_dofs[j])\n","        force_val.append(applied_force_vals[j])\n","        force_node.append(fnode)\n","    for i in range(len(force_val)) :\n","      force_val[i] /= 3   \n","\n","  if force_option == \"top_distributed\" :\n","    n_force = 2*(mesh.m1 - 1)\n","    for i in range(int(n_force/2)) :\n","      fnode = int( (mesh.m1+1)*(mesh.m2+1) - mesh.m1 + i)\n","      for j in range(mesh.dim) :\n","        force_dof.append(applied_force_dofs[j])\n","        force_val.append(applied_force_vals[j])\n","        force_node.append(fnode)\n","    for i in range(len(force_val)) :\n","      force_val[i] /= (n_force/2)   \n","\n","  return force_dof, force_node, force_val\n","\n","def assign_BC_option(mesh, applied_force_vals, applied_force_dofs, body_force,\n","                     support_option, force_option) :\n","\n","  # Displacement BC - !! count x and y separateley !!\n","  n_pre_disp, disp_node, disp_dof, disp_val = assign_supports(support_option, mesh)\n","\n"," #################################################################\n","\n","  # Body Forces\n","  elem_load = np.zeros((2, mesh.n_elem))\n","  for i in range(mesh.n_elem) :\n","    elem_load[0, i] = body_force[0]\n","    elem_load[1, i] = body_force[1]\n","\n","  force_dof, force_node, force_val = assign_force(support_option, force_option, mesh, applied_force_dofs, applied_force_vals) \n","\n","\n","  #################################################################\n","  # Processing\n","  # assign negative equation numnbes for nodes with prescribed displacements, else positive\n","  eq_num = np.zeros((2, mesh.n_node))\n","  for i in range(n_pre_disp) :\n","      node = disp_node[i]\n","      dof = disp_dof[i]\n","      eq_num[dof,node] = -i -1\n","  row = 0\n","  for i in range(mesh.n_node) :\n","      for j in range(2) :\n","          if eq_num[j,i] == 0 :\n","              row += 1\n","              eq_num[j,i] = row;\n","  n_dof = row\n","\n","  return BC(n_pre_disp, n_dof, eq_num, disp_dof, disp_node, disp_val, force_dof, force_node, force_val, elem_load)\n","\n","def build_mesh_L_bracket(elem_type, m1, m2, bound_x, bound_y, \n","               noise_type, noise_coord_scale, refine_fract) :\n","  # Building Mesh\n","  precision_base = 16\n","  dim = 2 # i.e. 2d\n","  nodes_per_elem = 4\n","  d1 = (bound_x[1] - bound_x[0])/m1\n","  d2 = (bound_y[1] - bound_y[0])/m2\n","  nodes_per_elem = 4\n","  n_elem = 2*m1 * m2\n","  n_node = 2*(m1 + 1) * (m2 + 1) - (m2 + 1)\n","\n","  # count coords row-wise, bottom to top, then apply noise\n","  coords = []\n","  for j in range(m2 + 1) :\n","    for i in range(m1 +1) :\n","      x = round(bound_x[0] + d1*i, precision_base)\n","      y = round(bound_y[0] + d2*j, precision_base)\n","      coords.append([x, y])\n","  # Add addition to L bracket\n","  for j in range(1, m1 + 1) :\n","    for i in range(m2 +1) :\n","      x = round(bound_x[0] + d1*i, precision_base)\n","      y = round(bound_y[1] + d2*j, precision_base)\n","      coords.append([x, y])\n","\n","  # Build elements ccw from bottom left\n","  elem_nodes = []\n","  for i in range(0, (m2-1) * (m1 + 1) + 1, m1 + 1) :\n","    for j in range(i, i + m1) :\n","      elem_node = []\n","      elem_node.append(j)\n","      elem_node.append(j + 1)\n","      elem_node.append(j + m1 + 2)\n","      elem_node.append(j + m1 + 1)\n","      elem_nodes.append(elem_node)\n","  # Add connection to L bracket\n","  for i in range(m2*(m1 + 1), m2*(m1 + 1) + m2 + 1, m2+1) :\n","    for j in range(i, i + m2) :\n","      elem_node = []\n","      elem_node.append(j)\n","      elem_node.append(j + 1)\n","      elem_node.append(j + m1 + 2)\n","      elem_node.append(j + m1 + 1)\n","      elem_nodes.append(elem_node)\n","  # Add new material to L bracket\n","  for i in range((m2+1)*(m1 + 1), (m2+1)*(m1 + 1) + m2*(m1 + 1)-1, m2 + 1) :\n","    for j in range(i, i + m2) :\n","      elem_node = []\n","      elem_node.append(j)\n","      elem_node.append(j + 1)\n","      elem_node.append(j + m2 + 2)\n","      elem_node.append(j + m2 + 1)\n","      elem_nodes.append(elem_node)\n","\n","  # Refine Mesh\n","  refined_coords = []\n","\n","  # Apply noise to coordinates\n","  coords = noise_mesh(elem_type, noise_type, noise_coord_scale,\n","                      refined_coords, coords, m1, m2, d1, d2)\n","\n","  return Mesh(dim, m1, m2, d1, d2, bound_x, bound_y, nodes_per_elem, n_elem, n_node, coords, elem_nodes)\n","\n","def build_mesh(elem_type, m1, m2, bound_x, bound_y, \n","               noise_type, noise_coord_scale, refine_fract) :\n","  # Building Mesh\n","  precision_base = 16\n","  dim = 2 # i.e. 2d\n","  nodes_per_elem = 4\n","  d1 = (bound_x[1] - bound_x[0])/m1\n","  d2 = (bound_y[1] - bound_y[0])/m2\n","  if elem_type == \"tri\" :\n","    nodes_per_elem = 3\n","    n_elem = 2 * m1 * m2\n","  else :\n","    nodes_per_elem = 4\n","    n_elem = m1 * m2\n","  n_node = (m1 + 1) * (m2 + 1)\n","\n","  # count coords row-wise, bottom to top, then apply noise\n","  coords = []\n","  for j in range(m2 + 1) :\n","    for i in range(m1 +1) :\n","      x = round(bound_x[0] + d1*i, precision_base)\n","      y = round(bound_y[0] + d2*j, precision_base)\n","      coords.append([x, y])\n","\n","  # Build elements ccw from bottom left\n","  # Build elements ccw from bottom left\n","  elem_nodes = []\n","  diag = 0\n","  for i in range(0, (m2-1) * (m1 + 1) + 1, m1 + 1) :\n","    for j in range(i, i + m1) :\n","      if elem_type == \"tri\" :\n","        if (diag % 2) == 0 :\n","          elem_node = []\n","          elem_node.append(j)\n","          elem_node.append(j + 1)\n","          elem_node.append(j + m1 + 1)\n","          elem_nodes.append(elem_node)\n","          elem_node = []\n","          elem_node.append(j + 1)\n","          elem_node.append(j + m1 + 2)\n","          elem_node.append(j + m1 + 1)\n","          elem_nodes.append(elem_node)\n","        else :\n","          elem_node = []\n","          elem_node.append(j)\n","          elem_node.append(j + m1 + 2)\n","          elem_node.append(j + m1 + 1)\n","          elem_nodes.append(elem_node)\n","          elem_node = []\n","          elem_node.append(j)\n","          elem_node.append(j + 1)\n","          elem_node.append(j + m1 + 2)\n","          elem_nodes.append(elem_node)\n","        diag += 1\n","      else :\n","        elem_node = []\n","        elem_node.append(j)\n","        elem_node.append(j + 1)\n","        elem_node.append(j + m1 + 2)\n","        elem_node.append(j + m1 + 1)\n","        elem_nodes.append(elem_node)\n","    diag += (m1%2) + 1\n","\n","  # Refine Mesh\n","  if elem_type == \"tri\" :\n","    refined_coords, coords, n_node, elem_nodes, n_elem = refine_mesh(\n","        refine_fract, coords, n_node, elem_nodes, n_elem)\n","  else :\n","    refined_coords = []\n","\n","  # Apply noise to coordinates\n","  coords = noise_mesh(elem_type, noise_type, noise_coord_scale,\n","                      refined_coords, coords, m1, m2, d1, d2)\n","\n","  return Mesh(dim, m1, m2, d1, d2, bound_x, bound_y, nodes_per_elem, n_elem, n_node, coords, elem_nodes)\n","\n","def build_mesh_hole(elem_type, m1, m2, bound_x, bound_y, \n","               noise_type, noise_coord_scale, refine_fract,\n","               center = [1.0, 0.0], radius = 0.0) :\n","  # Building Mesh\n","  precision_base = 8\n","  dim = 2 # i.e. 2d\n","  nodes_per_elem = 4\n","  d1 = (bound_x[1] - bound_x[0])/m1\n","  d2 = (bound_y[1] - bound_y[0])/m2\n","  nodes_per_elem = 4\n","  n_elem = m1 * m2\n","  n_node = (m1 + 1) * (m2 + 1)\n","  hole_density = [1]*n_elem\n","\n","\n","  # count coords row-wise, bottom to top, then apply noise\n","  # hole_bound_x = [center[0]-radius, center[0]+radius]\n","  # hole_bound_y = [center[1]-radius, center[1]+radius]\n","  # border_bound_x = [center[0]-radius-d1, center[0]+radius+d1]\n","  # border_bound_y = [center[1]-radius-d2, center[1]+radius+d2]\n","  border_bound_x = [center[0]-radius, center[0]+radius]\n","  border_bound_y = [center[1]-radius, center[1]+radius]\n","  hole_bound_x = [center[0]-radius+d1, center[0]+radius-d1]\n","  hole_bound_y = [center[1]-radius+d2, center[1]+radius-d2]\n","  node_i = 0\n","  coords = []\n","  skip_nodes = []\n","  border_nodes = []\n","  for j in range(m2 + 1) :\n","    for i in range(m1 +1) :\n","      x = round(bound_x[0] + d1*i, precision_base)\n","      y = round(bound_y[0] + d2*j, precision_base)\n","      if ((x >= hole_bound_x[0]) and (x <= hole_bound_x[1]) and \n","          (y >= hole_bound_y[0]) and (y <= hole_bound_y[1])) :\n","        skip_nodes.append(node_i)\n","        coords.append([x, y])\n","        # n_node -= 1\n","      elif ((x >= border_bound_x[0]) and (x <= border_bound_x[1]) and \n","        (y >= border_bound_y[0]) and (y <= border_bound_y[1])) :\n","        border_nodes.append(node_i)\n","        try :\n","          theta = np.arctan(np.abs( (y-center[1])/(x-center[0])))\n","        except :\n","          theta = np.pi/2\n","        x_delta = radius*np.cos(theta)\n","        y_delta = radius*np.sin(theta)\n","        if x <= center[0] : \n","          x = center[0] - x_delta\n","        else :\n","          x = center[0] + x_delta\n","        if y <= center[1] :\n","          y = center[1] - y_delta\n","        else :\n","          y = center[1] + y_delta\n","        coords.append([x, y])\n","      else :\n","        coords.append([x, y])\n","      node_i += 1\n","\n","\n","  # Build elements ccw from bottom left\n","  # Build elements ccw from bottom left\n","  elem_nodes = []\n","  elem_i = 0\n","  for i in range(0, (m2-1) * (m1 + 1) + 1, m1 + 1) :\n","    for j in range(i, i + m1) :\n","      elem_node = []\n","      elem_node.append(j)\n","      elem_node.append(j + 1)\n","      elem_node.append(j + m1 + 2)\n","      elem_node.append(j + m1 + 1)\n","      if all(i in border_nodes+skip_nodes for i in elem_node) :\n","        hole_density[elem_i] = 1e-6\n","      elem_nodes.append(elem_node)\n","      elem_i += 1\n","\n","  # Refine Mesh\n","  refined_coords = []\n","\n","  # Apply noise to coordinates\n","  coords = noise_mesh(elem_type, noise_type, noise_coord_scale,\n","                      refined_coords, coords, m1, m2, d1, d2)\n","  \n","  mesh = Mesh(dim, m1, m2, d1, d2, bound_x, bound_y, nodes_per_elem, n_elem, n_node, coords, elem_nodes)\n","\n","  return mesh, hole_density\n","\n","\n","def dual_mesh_pre_process_L_bracket(mesh_0, mesh_1) :\n","  M1 = mesh_0.m1\n","  M2 = mesh_0.m2\n","  m1 = mesh_1.m1\n","  m2 = mesh_1.m2\n","  m1_fact = int(m1/M1)\n","  m2_fact = int(m2/M2)\n","\n","  father_elems = []\n","  for i in range(0, (m2-1) * (m1 + 1) + 1, m2_fact*(m1 + 1)) :\n","    for j in range(i, (i + m1), m1_fact) :\n","      elem_node = []\n","      elem_node.append(j)\n","      elem_node.append(j + 1*m1_fact)\n","      elem_node.append(j + m1*m2_fact + m1_fact + m2_fact)\n","      elem_node.append(j + m1*m2_fact + m2_fact)\n","      father_elems.append(elem_node)\n","  # Add connection for L bracket\n","  for i in range(m2*(m1 + 1), m2*(m1 + 1) + m2 + 1, m2_fact*(m2+1)) :\n","    for j in range(i, i + m2, m1_fact) :\n","      elem_node = []\n","      elem_node.append(j)\n","      elem_node.append(j + m1_fact)\n","      elem_node.append(j + (m1+1) + (m2_fact-1)*(m2+1) + m1_fact)\n","      elem_node.append(j + (m1+1) + (m2_fact-1)*(m2+1))\n","      father_elems.append(elem_node)\n","  # Add new material to L bracket\n","  for i in range((m2+1)*(m1 + 1) + (m2_fact-1)*(m2+1), (m2+1)*(m1 + 1) + m2*(m1 + 1)-1, m2_fact*(m2+1)) :\n","    for j in range(i, i + m2, m1_fact) :\n","      elem_node = []\n","      elem_node.append(j)\n","      elem_node.append(j + 1*m1_fact)\n","      elem_node.append(j + m2*m2_fact + m1_fact + m2_fact)\n","      elem_node.append(j + m2*m2_fact + m2_fact)\n","      father_elems.append(elem_node)\n","\n","  graph_nodes = []\n","  for elem in father_elems[0:M1*M2] :\n","    graph_node = []\n","    for i in range(elem[0], elem[2] + 1, m1+1) :\n","      for j in range(i, i + 1 + m1_fact) :\n","        graph_node.append(j)\n","    graph_nodes.append(graph_node)\n","\n","  # add connection for L bracket\n","  for elem in father_elems[(M1*M2):((M1*M2) + M2)] :\n","    graph_node = []\n","    for i in range(elem[0], elem[0] + 2*(m1+1)-1, m1+1) :\n","      for j in range(i, i + 1 + m2_fact) :\n","        graph_node.append(j)\n","    for i in range(elem[0] + (m1+1) + (m2+1), elem[2] +1, m2+1) :\n","      for j in range(i, i + 1 + m2_fact) :\n","        graph_node.append(j)\n","    graph_nodes.append(graph_node)\n","\n","  # add material for L bracket\n","  for elem in father_elems[(M1*M2) + M2::] :\n","    graph_node = []\n","    for i in range(elem[0], elem[2] + 1, m2+1) :\n","      for j in range(i, i + 1 + m2_fact) :\n","        graph_node.append(j)\n","    graph_nodes.append(graph_node)\n","\n","  return father_elems, graph_nodes\n","\n","def assign_material(elem_type, mesh, E, v, elem_density) :\n","  # Material Assignment\n","  # Homogeneous, Isotropic Plane Stress\n","  elem_stiff = np.zeros((2, mesh.n_elem))\n","  for i in range(mesh.n_elem) :\n","    elem_stiff[0, i] = E\n","    elem_stiff[1, i] = v\n","    \n","  Ce = []\n","  for i in range(mesh.n_elem) :\n","    E_i = elem_stiff[0, i]\n","    v_i = elem_stiff[1, i]\n","    mu = 0.5*E_i/(1+v_i)\n","    lam = E_i*v_i/((1+v_i)*(1-2*v_i))\n","    if elem_type == \"tri\" :\n","      C = (E_i/(1-v_i**2)) * np.matrix([[1, v_i, 0],\n","                                [v_i, 1, 0],\n","                                [0, 0, (1-v_i)/2]])\n","    else : \n","      C = np.matrix([[lam+2*mu, 0, 0, lam],\n","                    [0, mu, mu, 0],\n","                    [0, mu, mu, 0],\n","                    [lam, 0, 0, lam+2*mu]])\n","    Ce.append(C)\n","  \n","  # Assign element density\n","  for i in range(mesh.n_elem) :\n","    Ce[i] = Ce[i] * elem_density[i]\n","\n","  return Material(E, v, elem_stiff, elem_density, Ce)\n","\n","\n","def assign_BC(mesh, applied_force_vals, applied_force_dofs, body_force) :\n","  \n","  \"\"\" Loading and BC for a cantilever \"\"\"\n","  \n","  # Displacement BC - !! count x and y separateley !!\n","  n_pre_disp = 0\n","  disp_node = []\n","  for i, point in enumerate(mesh.coords) :\n","    if point[0] == mesh.bound_x[0] :\n","      for j in range(mesh.dim) :\n","        disp_node.append(i)\n","        n_pre_disp += 1\n","\n","  disp_dof = []\n","  disp_val = []\n","  for i in range(0, n_pre_disp, mesh.dim) :\n","    disp_dof.append(0)\n","    disp_dof.append(1)\n","    disp_val.append(0)\n","    disp_val.append(0)\n","\n","#################################################################\n","\n","  # Body Forces\n","  elem_load = np.zeros((2, mesh.n_elem))\n","  for i in range(mesh.n_elem) :\n","    elem_load[0, i] = body_force[0]\n","    elem_load[1, i] = body_force[1]\n","\n","  # Nodal Forces - !! count F_x and F_y separateley !!\n","  force_dof = []\n","  force_node = []\n","  force_val = []\n","  n_force = 6\n","  for i in range(3) :\n","    fnode = int(mesh.m1 + (mesh.m1 + 1)*(mesh.m2/2 - 1 + i))\n","    for j in range(mesh.dim) :\n","      force_dof.append(applied_force_dofs[j])\n","      force_val.append(applied_force_vals[j])\n","      force_node.append(fnode)\n","  for i in range(len(force_val)) :\n","    force_val[i] /= 3    \n","\n","  # Bottom corner force:\n","  # n_force = 2\n","  # force_dof = []\n","  # force_node = []\n","  # force_val = []\n","  # for i in range(1) :\n","  #   fnode = int(m1 + (m1 + 1)*(i))\n","  #   for j in range(dim) :\n","  #     force_dof.append(force_dofs[j])\n","  #     force_val.append(force_vals[j])\n","  #     force_node.append(fnode)\n","  # for i in range(len(force_val)) :\n","  #   force_val[i] /= 1    \n","\n","\n","  #################################################################\n","  # Processing\n","  # assign negative equation numnbes for nodes with prescribed displacements, else positive\n","  eq_num = np.zeros((2, mesh.n_node))\n","  for i in range(n_pre_disp) :\n","      node = disp_node[i]\n","      dof = disp_dof[i]\n","      eq_num[dof,node] = -i -1\n","  row = 0\n","  for i in range(mesh.n_node) :\n","      for j in range(2) :\n","          if eq_num[j,i] == 0 :\n","              row += 1\n","              eq_num[j,i] = row;\n","  n_dof = row\n","\n","  return BC(n_pre_disp, n_dof, eq_num, disp_dof, disp_node, disp_val, force_dof, force_node, force_val, elem_load)\n","\n","def assemble_matrices(elem_type, mesh, material, bc, efficient_opt) :\n","  # Matrix Assembly\n","  # UP = np.zeros((bc.n_pre_disp, 2))\n","  # for i in range(bc.n_pre_disp) :\n","  #   node = bc.disp_node[i]\n","  #   dof = bc.disp_dof[i]\n","  #   u = bc.disp_val[i]\n","  #   row = int(-(bc.eq_num[dof, node]) - 1)\n","  #   UP[row, dof] = u\n","  UP = np.zeros((bc.n_pre_disp, 1))\n","  for i in range(bc.n_pre_disp) :\n","    node = bc.disp_node[i]\n","    dof = bc.disp_dof[i]\n","    u = bc.disp_val[i]\n","    row = int(-(bc.eq_num[dof, node]) - 1)\n","    UP[row] = u\n","\n","  PF = np.zeros((bc.n_dof, 1))\n","  for i in range(len(bc.force_val)) :\n","    node = bc.force_node[i]\n","    dof = bc.force_dof[i]\n","    f = bc.force_val[i]\n","    row = int(bc.eq_num[dof, node] - 1)\n","    if row >= 0 :\n","      PF[row, 0] += f\n","\n","  PP = np.zeros((bc.n_pre_disp, 1))\n","  KPP = np.zeros((bc.n_pre_disp, bc.n_pre_disp))\n","  KPF = np.zeros((bc.n_pre_disp, bc.n_dof))\n","  KFP = np.zeros((bc.n_dof, bc.n_pre_disp))\n","  KFF = np.zeros((bc.n_dof, bc.n_dof))\n","  UUR = np.zeros((mesh.dim, mesh.n_node))\n","  PUR = np.zeros((mesh.dim, mesh.n_node))\n","\n","  for elem_iter in range(mesh.n_elem) :\n","    \n","    K_el, P_el = element(elem_type, elem_iter, mesh, material, bc)\n","\n","    for i in range(mesh.nodes_per_elem) : \n","      i_node = mesh.elem_nodes[elem_iter][i]\n","\n","      for i_dof in range(2) : # loop over 2 dof\n","        row = int(bc.eq_num[i_dof, i_node])\n","        ii = 2 * i + i_dof\n","        \n","        for j in range(mesh.nodes_per_elem) : #build columns\n","          j_node = mesh.elem_nodes[elem_iter][j]\n","          for j_dof in range(2) :\n","            col = int(bc.eq_num[j_dof, j_node])\n","            jj = 2 * j + j_dof\n","\n","            if row > 0 :\n","              if col >  0 :\n","                KFF[row -1, col-1] += K_el[ii, jj]\n","              else :\n","                KFP[row-1, -col-1] += K_el[ii, jj]\n","            else :\n","              if col >  0 :\n","                KPF[-row-1, col-1] += K_el[ii, jj]\n","              else :\n","                KPP[-row-1, -col-1] += K_el[ii, jj]\n","        \n","        if row >= 0 :\n","          PF[row-1] += P_el[ii]\n","        else :\n","          PP[-row-1] += P_el[ii]\n","\n","  # Build swapped KUR to align with UUR\n","  if efficient_opt :\n","    KUR = np.concatenate([np.concatenate([KPP, KPF], axis = 1),\n","                        np.column_stack([KFP, KFF])],\n","                        axis = 0)\n","    old_uur_idx = 0\n","    p_idx = 0\n","    f_idx = len(bc.disp_node)\n","    swap = [] # tuples of (UUR_node, K_row)\n","    for i_node in range(mesh.n_node) :\n","      for i_dof in range(2) :\n","        row = int(bc.eq_num[i_dof, i_node])\n","        if row > 0 :\n","          swap.append((old_uur_idx, f_idx))\n","          f_idx+=1\n","        else :\n","          swap.append((old_uur_idx, p_idx))\n","          p_idx+=1\n","        old_uur_idx +=1\n","\n","    new_KUR =  KUR.copy()\n","    for pair in swap :\n","      temp_KUR = new_KUR\n","      # swap all first columns\n","      new_KUR[..., pair[0]] = temp_KUR[..., pair[1]]\n","      new_KUR[..., pair[1]] = temp_KUR[..., pair[0]]\n","      temp_KUR = new_KUR\n","      # swap whole rows\n","      new_KUR[pair[0], ...] = temp_KUR[pair[1], ...] \n","      new_KUR[pair[1], ...] = temp_KUR[pair[0], ...] \n","    new_KUR = scipy.sparse.csc_matrix(new_KUR)\n","\n","    return FEA(UP, PF, PP, KPP, KPF, KFP, KFF, new_KUR)\n","  else :\n","    return FEA(UP, PF, PP, KPP, KPF, KFP, KFF, 0)\n","\n","\n","\n","\n","def solve_FEA(mesh, bc, fea) :  \n","  UUR = np.zeros((mesh.dim, mesh.n_node))\n","  PUR = np.zeros((mesh.dim, mesh.n_node))\n","\n","  #Solve\n","  # UF = np.linalg.solve(fea.KFF, (fea.PF - np.matmul(fea.KFP, fea.UP)))\n","  UF = sparse_solve(scipy.sparse.csc_matrix(fea.KFF), scipy.sparse.csc_matrix((fea.PF - np.matmul(fea.KFP, fea.UP))))\n","  try :\n","    UF = UF.todense()\n","  except AttributeError :\n","    pass\n","  UF = UF.reshape((bc.n_dof,1))\n","\n","  R = np.matmul(fea.KPP, fea.UP) + np.matmul(fea.KPF, UF) - fea.PP\n","\n","  for i_node in range(mesh.n_node) :\n","    for i_dof in range(mesh.dim) :\n","      row = int(bc.eq_num[i_dof, i_node])\n","      if row > 0 :\n","        UUR[i_dof, i_node] = UF[row -1]\n","        PUR[i_dof, i_node] = fea.PF[row -1, 0]\n","      else :\n","        UUR[i_dof, i_node] = fea.UP[-row -1, 0]\n","        PUR[i_dof, i_node] = R[-row -1, 0]\n","\n","  return Results(UF, R, UUR, PUR)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4237263e0e9a>\"\u001b[0;36m, line \u001b[0;32m61\u001b[0m\n\u001b[0;31m    start = 0\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"]}]},{"cell_type":"markdown","metadata":{"id":"pl36BanWvyRv"},"source":["### Post Process, stress and strain"]},{"cell_type":"code","metadata":{"id":"yPOkAAosv2dE"},"source":["def get_stress_gauss(elem_type, mesh, material, results) :\n","  \"\"\"\n","  First Order Stress (r = 0) via Gauss Quad\n","  \"\"\"\n","  if elem_type == \"tri\" :\n","    nodes_per_elem = 3\n","  else :\n","    nodes_per_elem = 4\n","\n","  stress = np.zeros((nodes_per_elem, mesh.n_node))\n","  elem_stress = np.zeros((nodes_per_elem, mesh.n_elem))\n","  count  = np.zeros((1, mesh.n_node))\n","\n","  for elem_iter in range(mesh.n_elem) :\n","    x_el = np.zeros((nodes_per_elem, mesh.dim))\n","    u_el = np.zeros((nodes_per_elem, mesh.dim))\n","    for i in range(nodes_per_elem) :\n","      node = mesh.elem_nodes[elem_iter][i]\n","      x_el[i, ...] = np.asarray(mesh.coords[node])\n","      u_el[i, ...] = results.UUR[...,node]\n","\n","    # 1 Order GaussQuad\n","    if elem_type == \"tri\" :\n","      r = [1/3, 1/3]\n","      w = 2 + np.zeros((1,nodes_per_elem))\n","    else :\n","      r = [0, 0]\n","      w = 2 + np.zeros((1,nodes_per_elem))\n","    N, DN = shape_funct(elem_type, r)\n","    J = np.matmul(np.transpose(x_el), DN)\n","    detJ = J[0,0]*J[1,1] - J[0,1]*J[1,0]\n","    invJ = np.matrix([[J[1,1], -J[0,1]], [-J[1,0], J[0,0]]])/detJ\n","    \n","    B = np.matmul(DN, invJ)\n","    NhatToI = np.kron(np.transpose(N), np.eye(2))\n","    if elem_type == \"tri\" :\n","      BhatToI = np.zeros((3,6))\n","      BhatToI[0,0] = B[0][0,0]\n","      BhatToI[1,1] = B[0][0,1]\n","      BhatToI[0,2] = B[1][0,0]\n","      BhatToI[1,3] = B[1][0,1]\n","      BhatToI[0,4] = B[2][0,0]\n","      BhatToI[1,5] = B[2][0,1]\n","      BhatToI[2,0] = BhatToI[1,1]\n","      BhatToI[2,1] = BhatToI[0,0]\n","      BhatToI[2,2] = BhatToI[1,3]\n","      BhatToI[2,3] = BhatToI[0,2]\n","      BhatToI[2,4] = BhatToI[1,5]\n","      BhatToI[2,5] = BhatToI[0,4]\n","    else :\n","      BhatToI = np.kron(np.transpose(B), np.eye(2))\n","\n","    Du = np.matmul(BhatToI, ((u_el).reshape(2*nodes_per_elem,1)))\n","    S = np.matmul(material.Ce[elem_iter] , Du)\n","    \n","    for j in range(nodes_per_elem) :\n","      elem_stress[..., elem_iter][j] += S[j]\n","\n","    for i in range(nodes_per_elem) :\n","      col = mesh.elem_nodes[elem_iter][i]\n","      for j in range(nodes_per_elem) :\n","        stress[..., col][j] += S[j]\n","      count[...,col] += 1\n","\n","  for i in range(mesh.n_node) :\n","    divisor = count[..., i][0]\n","    stress[..., i] = stress[..., i]/divisor\n","  \n","  with warnings.catch_warnings():\n","    warnings.simplefilter(\"ignore\")\n","    if elem_type == \"quad\" :\n","      von_mises = (stress[0,...]**2 + stress[3,...]**2 - stress[0,...]*stress[3,...] + 3* stress[1,...]*stress[2,...] )**0.5\n","      von_mises_elem = (elem_stress[0,...]**2 + elem_stress[3,...]**2 - elem_stress[0,...]*elem_stress[3,...] + 3* elem_stress[1,...]*elem_stress[2,...] )**0.5\n","    else :\n","      stress = np.stack([stress[0,...], stress[2,...], stress[2,...], stress[1,...]], axis = 0)\n","      elem_stress = np.stack([elem_stress[0,...], elem_stress[2,...], elem_stress[2,...], elem_stress[1,...]], axis = 0)\n","      von_mises = (stress[0,...]**2 + stress[3,...]**2 - stress[0,...]*stress[3,...] + 3* stress[1,...]*stress[2,...] )**0.5\n","      von_mises_elem = (elem_stress[0,...]**2 + elem_stress[3,...]**2 - elem_stress[0,...]*elem_stress[3,...] + 3* elem_stress[1,...]*elem_stress[2,...] )**0.5\n","    \n","\n","  return np.column_stack([stress.T, von_mises.reshape(stress.T.shape[0], 1)]), np.column_stack([elem_stress.T, von_mises_elem.reshape(elem_stress.T.shape[0], 1)])\n","\n","def get_dU_gauss(elem_type, mesh, uur) :\n","  \"\"\"\n","  First Order Stress (r = 0) via Gauss Quad\n","  uur 2 x N_NODe\n","  \"\"\"\n","  if elem_type == \"tri\" :\n","    nodes_per_elem = 3\n","  else :\n","    nodes_per_elem = 4\n","\n","  stress = np.zeros((nodes_per_elem, mesh.n_node))\n","  elem_stress = np.zeros((nodes_per_elem, mesh.n_elem))\n","  count  = np.zeros((1, mesh.n_node))\n","\n","  for elem_iter in range(mesh.n_elem) :\n","    x_el = np.zeros((nodes_per_elem, mesh.dim))\n","    u_el = np.zeros((nodes_per_elem, mesh.dim))\n","    for i in range(nodes_per_elem) :\n","      node = mesh.elem_nodes[elem_iter][i]\n","      x_el[i, ...] = np.asarray(mesh.coords[node])\n","      u_el[i, ...] = uur[node, ...]\n","\n","    # 1 Order GaussQuad\n","    if elem_type == \"tri\" :\n","      r = [1/3, 1/3]\n","      w = 2 + np.zeros((1,nodes_per_elem))\n","    else :\n","      r = [0, 0]\n","      w = 2 + np.zeros((1,nodes_per_elem))\n","    N, DN = shape_funct(elem_type, r)\n","    J = np.matmul(np.transpose(x_el), DN)\n","    detJ = J[0,0]*J[1,1] - J[0,1]*J[1,0]\n","    invJ = np.matrix([[J[1,1], -J[0,1]], [-J[1,0], J[0,0]]])/detJ\n","    \n","    B = np.matmul(DN, invJ)\n","    NhatToI = np.kron(np.transpose(N), np.eye(2))\n","    if elem_type == \"tri\" :\n","      BhatToI = np.zeros((3,6))\n","      BhatToI[0,0] = B[0][0,0]\n","      BhatToI[1,1] = B[0][0,1]\n","      BhatToI[0,2] = B[1][0,0]\n","      BhatToI[1,3] = B[1][0,1]\n","      BhatToI[0,4] = B[2][0,0]\n","      BhatToI[1,5] = B[2][0,1]\n","      BhatToI[2,0] = BhatToI[1,1]\n","      BhatToI[2,1] = BhatToI[0,0]\n","      BhatToI[2,2] = BhatToI[1,3]\n","      BhatToI[2,3] = BhatToI[0,2]\n","      BhatToI[2,4] = BhatToI[1,5]\n","      BhatToI[2,5] = BhatToI[0,4]\n","    else :\n","      BhatToI = np.kron(np.transpose(B), np.eye(2))\n","\n","    Du = np.matmul(BhatToI, ((u_el).reshape(2*nodes_per_elem,1)))\n","    \n","    for j in range(nodes_per_elem) :\n","      elem_stress[..., elem_iter][j] += Du[j]\n","\n","    for i in range(nodes_per_elem) :\n","      col = mesh.elem_nodes[elem_iter][i]\n","      for j in range(nodes_per_elem) :\n","        stress[..., col][j] += Du[j]\n","      count[...,col] += 1\n","\n","  for i in range(mesh.n_node) :\n","    divisor = count[..., i][0]\n","    stress[..., i] = stress[..., i]/divisor\n","\n","  with warnings.catch_warnings():\n","    warnings.simplefilter(\"ignore\")\n","    if elem_type == \"quad\" :\n","      von_mises = (stress[0,...]**2 + stress[3,...]**2 - stress[0,...]*stress[3,...] + 3* stress[1,...]*stress[2,...] )**0.5\n","      von_mises_elem = (elem_stress[0,...]**2 + elem_stress[3,...]**2 - elem_stress[0,...]*elem_stress[3,...] + 3* elem_stress[1,...]*elem_stress[2,...] )**0.5\n","    else :\n","      stress = np.stack([stress[0,...], stress[2,...], stress[2,...], stress[1,...]], axis = 0)\n","      elem_stress = np.stack([elem_stress[0,...], elem_stress[2,...], elem_stress[2,...], elem_stress[1,...]], axis = 0)\n","      von_mises = (stress[0,...]**2 + stress[3,...]**2 - stress[0,...]*stress[3,...] + 3* stress[1,...]*stress[2,...] )**0.5\n","      von_mises_elem = (elem_stress[0,...]**2 + elem_stress[3,...]**2 - elem_stress[0,...]*elem_stress[3,...] + 3* elem_stress[1,...]*elem_stress[2,...] )**0.5\n","    \n","  return np.column_stack([stress.T, von_mises.reshape(stress.T.shape[0], 1)]), np.column_stack([elem_stress.T, von_mises_elem.reshape(elem_stress.T.shape[0], 1)])\n","\n","def get_stress_from_Du(elem_type, mesh, material, dU_elem) :\n","  \"\"\"\n","  First Order Stress (r = 0) via Gauss Quad\n","  \"\"\"\n","  if elem_type == \"tri\" :\n","    nodes_per_elem = 3\n","  else :\n","    nodes_per_elem = 4\n","\n","  stress = np.zeros((nodes_per_elem, mesh.n_node))\n","  elem_stress = np.zeros((nodes_per_elem, mesh.n_elem))\n","  count  = np.zeros((1, mesh.n_node))\n","\n","  for elem_iter in range(mesh.n_elem) :\n","    Du = dU_elem[elem_iter, ...].reshape(nodes_per_elem,1)\n","    S = np.matmul(material.Ce[elem_iter] , Du)\n","  \n","    for j in range(nodes_per_elem) :\n","      elem_stress[..., elem_iter][j] += S[j]\n","\n","    for i in range(nodes_per_elem) :\n","      col = mesh.elem_nodes[elem_iter][i]\n","      for j in range(nodes_per_elem) :\n","        stress[..., col][j] += S[j]\n","      count[...,col] += 1\n","\n","  for i in range(mesh.n_node) :\n","    divisor = count[..., i][0]\n","    stress[..., i] = stress[..., i]/divisor\n","\n","  \n","  with warnings.catch_warnings():\n","    warnings.simplefilter(\"ignore\")\n","    if elem_type == \"quad\" :\n","      von_mises = (stress[0,...]**2 + stress[3,...]**2 - stress[0,...]*stress[3,...] + 3* stress[1,...]*stress[2,...] )**0.5\n","      von_mises_elem = (elem_stress[0,...]**2 + elem_stress[3,...]**2 - elem_stress[0,...]*elem_stress[3,...] + 3* elem_stress[1,...]*elem_stress[2,...] )**0.5\n","    else :\n","      stress = np.stack([stress[0,...], stress[2,...], stress[2,...], stress[1,...]], axis = 0)\n","      elem_stress = np.stack([elem_stress[0,...], elem_stress[2,...], elem_stress[2,...], elem_stress[1,...]], axis = 0)\n","      von_mises = (stress[0,...]**2 + stress[3,...]**2 - stress[0,...]*stress[3,...] + 3* stress[1,...]*stress[2,...] )**0.5\n","      von_mises_elem = (elem_stress[0,...]**2 + elem_stress[3,...]**2 - elem_stress[0,...]*elem_stress[3,...] + 3* elem_stress[1,...]*elem_stress[2,...] )**0.5\n","    \n","  return np.column_stack([stress.T, von_mises.reshape(stress.T.shape[0], 1)]), np.column_stack([elem_stress.T, von_mises_elem.reshape(elem_stress.T.shape[0], 1)])\n","\n","def get_disp_err(s, m) :\n","  \"\"\" \n","  Inputs : simulated UUR, modeled UUR as [N_NODE X 2]\n","  Returns : Nodal displacement error, avg, max, min\n","  \"\"\"\n","  err = []\n","  err_abs = []\n","  for i in range(len(m)) :\n","      disp_s = (s[i][0]**2 + s[i][1]**2)**0.5\n","      disp_m = (m[i][0]**2 + m[i][1]**2)**0.5\n","      if disp_s != 0 :\n","          err.append((((disp_m - disp_s)/disp_s)))\n","          err_abs.append((((disp_m - disp_s)/disp_s)**2)**0.5)\n","      else :\n","          err.append((((disp_m - disp_s))))\n","          err_abs.append((((disp_m - disp_s))**2)**0.5)\n","\n","  return err, sum(err_abs)/len(err), max(err), min(err)\n","\n","def get_vect_err(s, m) :\n","  \"\"\" \n","  Inputs : simulated vector, modeled stress col\n","  Returns : vect error\n","  \"\"\"\n","  err = []\n","  err_abs = []\n","  for i in range(len(m)) :\n","      disp_s = s[i][0]\n","      disp_m = m[i][0]\n","      if disp_s != 0 :\n","          err.append((((disp_m - disp_s)/disp_s)))\n","          err_abs.append((((disp_m - disp_s)/disp_s)**2)**0.5)\n","      else :\n","          err.append((((disp_m - disp_s))))\n","          err_abs.append((((disp_m - disp_s))**2)**0.5)\n","\n","  return err, sum(err_abs)/len(err), max(err), min(err)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E6vEtqASjsko"},"source":["### Commpliance"]},{"cell_type":"code","metadata":{"id":"r-E81cCmJH3G"},"source":["def compliance_viaP(bc, results) :\n","  \"\"\" returns U' K U == U'PUR for values at force_node \"\"\"\n","  compliance = 0\n","  for index in bc.force_node :\n","    compliance += results.UUR[0, index] * results.PUR[0, index]\n","    compliance += results.UUR[1, index] * results.PUR[1, index]\n","  compliance = compliance/2\n","\n","  return compliance\n","\n","def compliance_viaKUR(fea, results) :\n","  \"\"\" returns U' K U == U'PUR  \"\"\"\n","  UUR_stack = results.UUR[..., 0:1]\n","  for i in range(1, len( results.UUR[0, ...])) :\n","    UUR_stack = np.concatenate([UUR_stack, results.UUR[..., i:i+1] ] )\n","  \n","  return np.dot( UUR_stack.T, np.matmul(fea.KUR, UUR_stack) )[0][0]\n","\n","def compliance_viaKUR_mod(KUR, UUR) :\n","  \"\"\" returns U' K U == U'PUR  \"\"\"\n","  UUR_stack = UUR[..., 0:1]\n","  for i in range(1, len( UUR[0, ...])) :\n","    UUR_stack = np.concatenate([UUR_stack, UUR[..., i:i+1] ] )\n","  \n","  return np.dot( UUR_stack.T, np.matmul(KUR, UUR_stack) )[0][0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jSmrpN_kjuzW"},"source":["### Convergence"]},{"cell_type":"code","metadata":{"id":"j1sWoFnFJwBs"},"source":["def project_known_displacement(m1_a, m2_a, m1_b, m2_b, uur_a) :\n","  \"\"\" projects from [a], known fine-mesh, to [b], unknown coarse-mesh \n","  ONLY WORKS if m1_a, m2_a are integer multiples of m1_b, m2_b\n","  \"\"\"\n","  precision_base = 8\n","  d1_a = (bound_x[1] - bound_x[0])/m1_a\n","  d2_a = (bound_y[1] - bound_y[0])/m2_a\n","  d1_b = (bound_x[1] - bound_x[0])/m1_b\n","  d2_b = (bound_y[1] - bound_y[0])/m2_b\n","\n","  n_node_a = (m1_a + 1) * (m2_a + 1)\n","  n_node_b = (m1_b + 1) * (m2_b + 1)\n","\n","  # count coords row-wise, bottom to top, then apply noise\n","  coords_a = []\n","  for j in range(m2_a + 1) :\n","    for i in range(m1_a +1) :\n","      x = round(bound_x[0] + d1_a*i, precision_base)\n","      y = round(bound_y[0] + d2_a*j, precision_base)\n","      coords_a.append([x, y])\n","  coords_b = []\n","  for j in range(m2_b + 1) :\n","    for i in range(m1_b +1) :\n","      x = round(bound_x[0] + d1_b*i, precision_base)\n","      y = round(bound_y[0] + d2_b*j, precision_base)\n","      coords_b.append([x, y])\n","\n","  # project displacement from a to b, there must be one node within one element of the fine mesh\n","  uur_b = np.zeros((n_node_b, 2))\n","\n","  count = 0\n","  for (i_b, (x_b, y_b)) in enumerate(coords_b) :\n","    nearest_neighbors = []\n","    for (i_a, (x_a, y_a)) in enumerate(coords_a) :\n","      if (x_b == x_a) and (y_b == y_a) :\n","        uur_b[i_b] = uur_a[i_a]\n","        break\n","\n","  return uur_b"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g7B3xt9rnzUx"},"source":["# **Build graph from mesh**\n","\n","`get_input_graph_informed(elem_type, mesh, bc)` \\\n","*Uses projected values from coarse mesh*\\\n","\\\n","Globals :  [body_force_x, body_force_y]\\\n","Nodes : [x, y, is_pre_x, is_pre_y, is_forced_x, is_forced_y, avg_density, is_surface, is_void]\\\n","++ \n","[1hot, u_x, u_y, P_x, P_y, du11, du21, du12, du22, Sh]__projection \\\n","\n","Edges : [x, y, del_x, del_y, length, elem_density, is_void]\\\n","++\n","[d_u_x, d_u_y, d_P_x, d_P_y, d_du11, d_du21, d_du12, d_du22, d_Sh]__projection\n","\\\n","\\\n","`get_output_graph_informed(elem_type, input_graph, mesh, FEA, S, Du)` \\\n","\\*Adds delta_projected values from coarse mesh*\\\n","\\\n","Globals :  [body_force_x, body_force_y]\\\n","Nodes : [u_x, u_y, P_x, P_y, du11, du21, du12, du22, Sh]\\\n","++\n","[d_u_x, d_u_y, d_P_x, d_P_y, d_du11, d_du21, d_du12, d_du22, d_Sh] __delta projection  \\\n","\n","Edges : [del_length_x, del_length_y, length, delu11, delu21, delu12, delu22, delSh]\n","++\\\n","[d_u_x, d_u_y, d_P_x, d_P_y, d_du11, d_du21, d_du12, d_du22, d_Sh]__delta projection "]},{"cell_type":"code","metadata":{"id":"zJhIizkjK5FY"},"source":["def dual_mesh_pre_process(mesh_0, mesh_1) :\n","  \"\"\" captures the shared nodes and elements from a coarse mesh_0 and fine mesh mesh_1\"\"\"\n","  M1 = mesh_0.m1\n","  M2 = mesh_0.m2\n","  m1 = mesh_1.m1\n","  m2 = mesh_1.m2\n","  m1_fact = int(m1/M1)\n","  m2_fact = int(m2/M2)\n","  father_elems = []\n","  for i in range(0, (m2-1) * (m1 + 1) + 1, m2_fact*(m1 + 1)) :\n","    for j in range(i, (i + m1), m1_fact) :\n","      elem_node = []\n","      elem_node.append(j)\n","      elem_node.append(j + 1*m1_fact)\n","      elem_node.append(j + m1*m2_fact + m1_fact + m2_fact)\n","      elem_node.append(j + m1*m2_fact + m2_fact)\n","      father_elems.append(elem_node)\n","\n","  graph_nodes = []\n","  for elem in father_elems :\n","    graph_node = []\n","    for i in range(elem[0], elem[2] + 1, m1+1) :\n","      for j in range(i, i + 1 + m1_fact) :\n","        graph_node.append(j)\n","    graph_nodes.append(graph_node)\n","\n","  return father_elems, graph_nodes\n","\n","def multiscale_approximation(mesh_0, mesh_1, graph_nodes, output_graph_0) :\n","  \"\"\" projects a coarse approximation mesh_0, output_graph_0\n","  onto a fine mesh_1 using graph_nodes\"\"\"\n","  x_coarse, y_coarse = np.asarray(mesh_0.coords).T\n","  x_fine, y_fine = np.asarray(mesh_1.coords).T\n","\n","  project_values = np.zeros((mesh_1.n_node, 9))\n","  for father_elem, fine_nodes in enumerate(graph_nodes) :\n","    coarse_nodes = mesh_0.elem_nodes[father_elem]\n","    for fine_node in fine_nodes :\n","      distance = []\n","      father_values = []\n","      for coarse_node in coarse_nodes :\n","        distance.append( ((x_fine[fine_node] - x_coarse[coarse_node])**2 + (y_fine[fine_node] - y_coarse[coarse_node])**2)**0.5 )\n","        father_values.append(output_graph_0[\"nodes\"][coarse_node, 0::])\n","      scale_fine_to_coarse = (distance / max(distance))\n","      scale_fine_to_coarse = 1 - scale_fine_to_coarse / np.linalg.norm(scale_fine_to_coarse, ord = 2)\n","      scale_fine_to_coarse = (scale_fine_to_coarse / sum(scale_fine_to_coarse))\n","      \n","      project_values[fine_node] = np.matmul(np.asarray(father_values).T, scale_fine_to_coarse)\n","\n","  return project_values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pr3KBMWOvgPL"},"source":["def get_input_graph(elem_type, mesh, bc, element_density, surf_nodes, void_nodes) :\n","  \"\"\" \n","  9 nodes: [x, y, 1ux, 1uy, 1Fx, 1Fy, rho, 1surf, 1void]\n","  7 edges: [x, y, del_x, del_y, length, rho_edges, 1void]\n","  \"\"\"\n","  precision_base = 32\n","  #Globals\n","  # [body_force_x, body_force_y]\n","  globals = bc.elem_load[..., 0]\n","\n","  #Nodes\n","  nodes = np.zeros((mesh.n_node, 9))\n","\n","  node_density = np.zeros((mesh.n_node, 1))\n","  node_count = np.zeros((mesh.n_node, 1))\n","  for i, elem in enumerate(mesh.elem_nodes) :\n","    for node in elem :\n","      node_density[node] += element_density[i]\n","      node_count[node] += 1\n","  node_density /= node_count\n","\n","  for i in range(mesh.n_node) :\n","    nodes[i, 0:2] = mesh.coords[i]\n","    nodes[i, 6] = node_density[i]\n","    nodes[i, 7] = surf_nodes[i]\n","    nodes[i, 8] = void_nodes[i]\n","\n","  for i in range(len(bc.disp_node)) :\n","    if bc.disp_dof[i] == 0 :\n","      nodes[bc.disp_node[i], 2] = 1\n","    if bc.disp_dof[i] == 1 :\n","      nodes[bc.disp_node[i], 3] = 1\n","\n","  for i in range(len(bc.force_node)) :\n","    if bc.force_dof[i] == 0 :\n","      nodes[bc.force_node[i], 4] = 1\n","    if bc.force_dof[i] == 1 :\n","      nodes[bc.force_node[i], 5] = 1\n","\n","  # Edges \n","  # [x, y, del_x, del_y, displacement]\n","  # Connected both ways along mesh boundaries\n","  senders = []\n","  receivers = []\n","  e_x = []\n","  e_y = []\n","  del_x = []\n","  del_y = []\n","  displacement = []\n","\n","  send_rec = set()\n","  for elem in mesh.elem_nodes : \n","    if elem_type == \"tri\" :\n","      if elem[0] < elem[1] :\n","        send_rec.add((elem[0], elem[1]))\n","      else :\n","        send_rec.add((elem[1], elem[0]))\n","      if elem[1] < elem[2] :\n","        send_rec.add((elem[1], elem[2]))\n","      else :\n","        send_rec.add((elem[2], elem[1]))\n","      if elem[0] < elem[2] :\n","        send_rec.add((elem[0], elem[2]))\n","      else :\n","        send_rec.add((elem[2], elem[0]))\n","    else :\n","      if elem[0] < elem[1] :\n","        send_rec.add((elem[0], elem[1]))\n","      else :\n","        send_rec.add((elem[1], elem[0]))\n","      if elem[1] < elem[2] :\n","        send_rec.add((elem[1], elem[2]))\n","      else :\n","        send_rec.add((elem[2], elem[1]))\n","      if elem[2] < elem[3] :\n","        send_rec.add((elem[2], elem[3]))\n","      else :\n","        send_rec.add((elem[3], elem[2]))\n","      if elem[0] < elem[3] :\n","        send_rec.add((elem[0], elem[3]))\n","      else :\n","        send_rec.add((elem[3], elem[0]))\n","\n","  send_rec = list(send_rec)\n","  for i in range(len(send_rec)) :\n","    a = send_rec[i][0]\n","    b = send_rec[i][1]\n","    senders.append(a)\n","    senders.append(b)\n","    receivers.append(b)\n","    receivers.append(a)\n","    x = round( (mesh.coords[b][0] + mesh.coords[a][0])/2,\n","              precision_base)\n","    y = round( (mesh.coords[b][1] + mesh.coords[a][1])/2,\n","          precision_base)\n","    dx = round( (mesh.coords[b][0] - mesh.coords[a][0]),\n","              precision_base)\n","    dy = round( (mesh.coords[b][1] - mesh.coords[a][1]),\n","              precision_base)  \n","    displacement.append((dx**2 + dy**2) **0.5) \n","    displacement.append(displacement[-1])    \n","    e_x.append(x)\n","    e_y.append(y)\n","    e_x.append(x)\n","    e_y.append(y)\n","    del_x.append(dx)\n","    del_x.append(-dx )\n","    del_y.append(dy)\n","    del_y.append(-dy)\n","\n","  edges = np.zeros((len(senders), 7)) \n","  for i in range(len(senders)) :\n","    edges[i,0] = e_x[i]\n","    edges[i,1] = e_y[i]\n","    edges[i,2] = del_x[i]\n","    edges[i,3] = del_y[i]\n","    edges[i,4] = displacement[i]\n","  \n","  for i, (send, rec) in enumerate(zip(senders, receivers)) :\n","    for elem_num, elem in enumerate(mesh.elem_nodes) :\n","      if (send in elem) and (rec in elem) : \n","        edges[i,5] += element_density[elem_num] / 2\n","    if nodes[send, 8] == 1 or nodes[rec, 8] == 1 :\n","      edges[i,6] = 1\n","\n","  input_graph = {\"globals\": np.asarray(globals).astype('float64') ,\n","                        \"nodes\": nodes.astype('float64') ,\n","                        \"edges\": edges.astype('float64') ,\n","                        \"receivers\": receivers,\n","                        \"senders\": senders\n","                        }\n","  return input_graph\n","\n","\n","\n","def get_input_graph_dual_informed(elem_type, mesh, bc, element_density, surf_nodes, void_nodes,\n","                             father_stat_list, father_projection_list, graph_node_list_projection,\n","                             mesh_projection, output_graph_projection) :\n","  \n","  \"\"\" \n","  Uses infromation from the projection in attributes.\n","  19 nodes: [x, y, 1ux, 1uy, +-1Fx, +-1Fy, rho, 1surf, 1void, \n","            1father_node, ux, uy, Fx, Fy, du_xx, du_yx, du_xy, du_yy, sig_vonmises]\n","  16 edges: [x, y, del_x, del_y, length, rho_edges, 1void, \n","            del_ux, del_uy, del_Fx, del_Fy, del_du_xx, del_du_yx, del_du_xy, del_du_yy, del_sig_vonmises]\n","  \"\"\"\n","  precision_base = 32\n","  #Globals\n","  # [body_force_x, body_force_y]\n","  globals = bc.elem_load[..., 0]\n","\n","  #Nodes\n","  nodes = np.zeros((mesh.n_node, 19))\n","\n","  node_density = np.zeros((mesh.n_node, 1))\n","  node_count = np.zeros((mesh.n_node, 1))\n","  for i, elem in enumerate(mesh.elem_nodes) :\n","    for node in elem :\n","      node_density[node] += element_density[i]\n","      node_count[node] += 1\n","  node_density /= node_count\n","\n","  for i in range(mesh.n_node) :\n","    nodes[i, 0:2] = mesh.coords[i]\n","    nodes[i, 6] = node_density[i]\n","    nodes[i, 7] = surf_nodes[i]\n","    nodes[i, 8] = void_nodes[i]\n","\n","  for i in range(len(bc.disp_node)) :\n","    if bc.disp_dof[i] == 0 :\n","      nodes[bc.disp_node[i], 2] = 1\n","    if bc.disp_dof[i] == 1 :\n","      nodes[bc.disp_node[i], 3] = 1\n","\n","  for i in range(len(bc.force_node)) :\n","    if bc.force_dof[i] == 0 :\n","      nodes[bc.force_node[i], 4] = bc.force_val[0]/(1e-6 + np.abs(bc.force_val[0]))\n","    if bc.force_dof[i] == 1 :\n","      nodes[bc.force_node[i], 5] = bc.force_val[1]/(1e-6 + np.abs(bc.force_val[1]))\n","\n","  # Edges \n","  # [x, y, del_x, del_y, displacement]\n","  # Connected both ways along mesh boundaries\n","  senders = []\n","  receivers = []\n","  e_x = []\n","  e_y = []\n","  del_x = []\n","  del_y = []\n","  displacement = []\n","\n","  send_rec = set()\n","  for elem in mesh.elem_nodes : \n","    if elem_type == \"tri\" :\n","      if elem[0] < elem[1] :\n","        send_rec.add((elem[0], elem[1]))\n","      else :\n","        send_rec.add((elem[1], elem[0]))\n","      if elem[1] < elem[2] :\n","        send_rec.add((elem[1], elem[2]))\n","      else :\n","        send_rec.add((elem[2], elem[1]))\n","      if elem[0] < elem[2] :\n","        send_rec.add((elem[0], elem[2]))\n","      else :\n","        send_rec.add((elem[2], elem[0]))\n","    else :\n","      if elem[0] < elem[1] :\n","        send_rec.add((elem[0], elem[1]))\n","      else :\n","        send_rec.add((elem[1], elem[0]))\n","      if elem[1] < elem[2] :\n","        send_rec.add((elem[1], elem[2]))\n","      else :\n","        send_rec.add((elem[2], elem[1]))\n","      if elem[2] < elem[3] :\n","        send_rec.add((elem[2], elem[3]))\n","      else :\n","        send_rec.add((elem[3], elem[2]))\n","      if elem[0] < elem[3] :\n","        send_rec.add((elem[0], elem[3]))\n","      else :\n","        send_rec.add((elem[3], elem[0]))\n","\n","  send_rec = list(send_rec)\n","  for i in range(len(send_rec)) :\n","    a = send_rec[i][0]\n","    b = send_rec[i][1]\n","    senders.append(a)\n","    senders.append(b)\n","    receivers.append(b)\n","    receivers.append(a)\n","    x = round( (mesh.coords[b][0] + mesh.coords[a][0])/2,\n","              precision_base)\n","    y = round( (mesh.coords[b][1] + mesh.coords[a][1])/2,\n","          precision_base)\n","    dx = round( (mesh.coords[b][0] - mesh.coords[a][0]),\n","              precision_base)\n","    dy = round( (mesh.coords[b][1] - mesh.coords[a][1]),\n","              precision_base)  \n","    displacement.append((dx**2 + dy**2) **0.5) \n","    displacement.append(displacement[-1])    \n","    e_x.append(x)\n","    e_y.append(y)\n","    e_x.append(x)\n","    e_y.append(y)\n","    del_x.append(dx)\n","    del_x.append(-dx )\n","    del_y.append(dy)\n","    del_y.append(-dy)\n","\n","  edges = np.zeros((len(senders), 16)) \n","  for i in range(len(senders)) :\n","    edges[i,0] = e_x[i]\n","    edges[i,1] = e_y[i]\n","    edges[i,2] = del_x[i]\n","    edges[i,3] = del_y[i]\n","    edges[i,4] = displacement[i]\n","  \n","  for i, (send, rec) in enumerate(zip(senders, receivers)) :\n","    for elem_num, elem in enumerate(mesh.elem_nodes) :\n","      if (send in elem) and (rec in elem) : \n","        edges[i,5] += element_density[elem_num] / 2\n","    if nodes[send, 8] == 1 or nodes[rec, 8] == 1 :\n","      edges[i,6] = 1\n","\n","\n","  # MULTISCALE \n","  for refined_node in flat_list(father_stat_list) :\n","    nodes[refined_node, 9] = 1.0\n","  nodes[..., 10:19] = multiscale_approximation(mesh_projection, mesh, graph_node_list_projection, output_graph_projection)\n","\n","  for i, (send, rec) in enumerate(zip(senders, receivers)) :\n","    edges[i, 7:16] = nodes[rec, 10:19] - nodes[send, 10:19]\n","\n","\n","  input_graph = {\"globals\": np.asarray(globals).astype('float64') ,\n","                        \"nodes\": nodes.astype('float64') ,\n","                        \"edges\": edges.astype('float64') ,\n","                        \"receivers\": receivers,\n","                        \"senders\": senders\n","                        }\n","  return input_graph\n","\n","def get_input_graph_multiscale_informed(elem, input_graph_0, input_graph_1, output_graph_0, output_graph_1, graph_node_list, father_elem_node_list, mesh_0) :\n","  \n","  \"\"\" \n","  Builds subgraphs using infromation from the projection in attributes.\n","  19 nodes: [x, y, 1ux, 1uy, +-1Fx, +-1Fy, rho, 1surf, 1void, \n","            1father_node, ux, uy, Fx, Fy, du_xx, du_yx, du_xy, du_yy, sig_vonmises]\n","  16 edges: [x, y, del_x, del_y, length, rho_edges, 1void, \n","            del_ux, del_uy, del_Fx, del_Fy, del_du_xx, del_du_yx, del_du_xy, del_du_yy, del_sig_vonmises]\n","  \"\"\"\n","\n","  #Globals\n","  # [body_force_x, body_force_y]\n","  globals = input_graph_0[\"globals\"]\n","\n","  #Nodes\n","  n_nodes = len(graph_node_list)\n","  nodes = np.zeros((n_nodes, 19))\n","  for i, node in enumerate(graph_node_list) :\n","    nodes[i, ...] = input_graph_1[\"nodes\"][node, ...]\n","\n","  # for i, refined_node in enumerate(father_elem_node_list) :\n","  #   idx = graph_node_list.index(refined_node)\n","  #   nodes[idx, 9] = 1.0\n","    # nodes[idx, 10:19] = output_graph_0[\"nodes\"][node, 0:9][mesh_0.elem_nodes[elem][i]]\n","\n","  # Edges\n","  global_senders = []\n","  global_receivers = []\n","  global_edge_id_list = [] # global ids for \n","  for edge, (a, b) in enumerate( zip(output_graph_1[\"senders\"], output_graph_1[\"receivers\"]) ) :\n","    if (a in graph_node_list) and (b in graph_node_list) :\n","      global_senders.append(a)\n","      global_receivers.append(b)\n","      global_edge_id_list.append(edge)\n","\n","  new_senders = []\n","  new_receivers = []\n","  for s, r in zip(global_senders, global_receivers) :\n","    new_senders.append(graph_node_list.index(s))\n","    new_receivers.append(graph_node_list.index(r))\n","\n","  n_edges = len(new_senders)\n","  edges = np.zeros((n_edges, 16))\n","  for local_id, global_edge in enumerate(global_edge_id_list) :\n","    edges[local_id, 0:16] = input_graph_1[\"edges\"][global_edge]\n","\n","  input_graph = {\"globals\": np.asarray(globals).astype('float64') ,\n","                        \"nodes\": nodes.astype('float64') ,\n","                        \"edges\": edges.astype('float64') ,\n","                        \"receivers\": new_receivers,\n","                        \"senders\": new_senders\n","                        }\n","\n","  return input_graph, global_edge_id_list\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bE4yJHmmQ3Yz"},"source":["def get_output_graph(elem_type, input_graph, mesh, results, Stress, Du) :\n","\n","  \"\"\" \n","  Uses high-fidelity analysis\n","  9 nodes: [ux, uy, Fx, Fy, du_xx, du_yx, du_xy, du_yy, sig_vonmises]\n","  8 edges: [del_ux, del_uy, final_length, del_du_xx, del_du_yx, del_du_xy, del_du_yy, del_sig_vonmises]\n","  \"\"\"\n","  # Reuse Globals, senders, receivers\n","  # [body_force_x, body_force_y]\n","  globals = input_graph[\"globals\"]\n","  senders = input_graph[\"senders\"]\n","  receivers = input_graph[\"receivers\"]\n","\n","  #Nodes\n","  nodes = np.zeros((mesh.n_node, 9))\n","\n","  for i in range(mesh.n_node) :\n","    nodes[i, 0] = results.UUR[0,i]\n","    nodes[i, 1] = results.UUR[1,i]\n","    nodes[i, 2] = results.PUR[0,i]\n","    nodes[i, 3] = results.PUR[1,i]\n","    nodes[i, 4] = Du[i, 0]\n","    nodes[i, 5] = Du[i, 1]\n","    nodes[i, 6] = Du[i, 2]\n","    nodes[i, 7] = Du[i, 3]\n","    nodes[i, 8] = Stress[i, 4]\n","\n","    \n","  # Edges\n","  # [del_x, del_y, length, delS...]\n","  disp_coords = np.transpose(results.UUR) + mesh.coords\n","  del_x = []\n","  del_y = []\n","  displacement = []\n","  for i in range(len(senders)) :\n","    a = senders[i]\n","    b = receivers[i]\n","\n","    dx = round( (disp_coords[b][0] - disp_coords[a][0]),\n","              precision_base)\n","    dy = round( (disp_coords[b][1] - disp_coords[a][1]),\n","              precision_base)  \n","    displacement.append((dx**2 + dy**2) **0.5) \n","    del_x.append(dx)\n","    del_y.append(dy)\n","\n","  edges = np.zeros((len(senders), 8)) \n","  for i in range(len(senders)) :\n","    edges[i,0] = del_x[i] - input_graph[\"edges\"][i,2] \n","    edges[i,1] = del_y[i] - input_graph[\"edges\"][i,3] \n","    edges[i,2] = displacement[i]\n","\n","  for i, (send, rec) in enumerate(zip(senders, receivers)) :\n","    edges[i, 3] = nodes[rec, 4] - nodes[send, 4]\n","    edges[i, 4] = nodes[rec, 5] - nodes[send, 5]\n","    edges[i, 5] = nodes[rec, 6] - nodes[send, 6]\n","    edges[i, 6] = nodes[rec, 7] - nodes[send, 7]\n","    edges[i, 7] = nodes[rec, 8] - nodes[send, 8]\n","\n","  output_graph = {\"globals\": np.asarray(globals).astype('float64') ,\n","                        \"nodes\": nodes.astype('float64') ,\n","                        \"edges\": edges.astype('float64') ,\n","                        \"receivers\": receivers,\n","                        \"senders\": senders\n","                        }\n","  return output_graph\n","\n","def get_output_graph_informed(elem_type, input_graph, mesh, results, Stress, Du) :\n","  \"\"\" \n","  Uses high-fidelity analysis, including the change in attribute relative to the low-fi analysis\n","  18 nodes: [ux, uy, Fx, Fy, du_xx, du_yx, du_xy, du_yy, sig_vonmises,\n","            del_ux, del_uy, del_Fx, del_Fy, del_du_xx, del_du_yx, del_du_xy, del_du_yy, del_sig_vonmises]\n","  17 edges: [del_ux, del_uy, final_length, del_du_xx, del_du_yx, del_du_xy, del_du_yy, del_sig_vonmises,\n","            del_ux, del_uy, del_Fx, del_Fy, del_du_xx, del_du_yx, del_du_xy, del_du_yy, del_sig_vonmises]\n","  \"\"\"\n","  # Reuse Globals, senders, receivers\n","  # [body_force_x, body_force_y]\n","  globals = input_graph[\"globals\"]\n","  senders = input_graph[\"senders\"]\n","  receivers = input_graph[\"receivers\"]\n","\n","  #Nodes\n","  nodes = np.zeros((mesh.n_node, 18))\n","\n","  for i in range(mesh.n_node) :\n","    nodes[i, 0] = results.UUR[0,i]\n","    nodes[i, 1] = results.UUR[1,i]\n","    nodes[i, 2] = results.PUR[0,i]\n","    nodes[i, 3] = results.PUR[1,i]\n","    nodes[i, 4] = Du[i, 0]\n","    nodes[i, 5] = Du[i, 1]\n","    nodes[i, 6] = Du[i, 2]\n","    nodes[i, 7] = Du[i, 3]\n","    nodes[i, 8] = Stress[i, 4]\n","  nodes[..., 9:18] = nodes[..., 0:9] - input_graph[\"nodes\"][..., 10:19]\n","\n","    \n","  # Edges\n","  # [del_x, del_y, length, delS...]\n","  disp_coords = np.transpose(results.UUR) + mesh.coords\n","  del_x = []\n","  del_y = []\n","  displacement = []\n","  for i in range(len(senders)) :\n","    a = senders[i]\n","    b = receivers[i]\n","\n","    dx = round( (disp_coords[b][0] - disp_coords[a][0]),\n","              precision_base)\n","    dy = round( (disp_coords[b][1] - disp_coords[a][1]),\n","              precision_base)  \n","    displacement.append((dx**2 + dy**2) **0.5) \n","    del_x.append(dx)\n","    del_y.append(dy)\n","\n","  edges = np.zeros((len(senders), 17)) \n","  for i in range(len(senders)) :\n","    edges[i,0] = del_x[i] - input_graph[\"edges\"][i,2] \n","    edges[i,1] = del_y[i] - input_graph[\"edges\"][i,3] \n","    edges[i,2] = displacement[i]\n","\n","  for i, (send, rec) in enumerate(zip(senders, receivers)) :\n","    edges[i, 3:8] = nodes[rec, 4:9] - nodes[send, 4:9]\n","    edges[i, 8:17] = nodes[rec, 9:18] - nodes[send, 9:18]\n","\n","  output_graph = {\"globals\": np.asarray(globals).astype('float64') ,\n","                        \"nodes\": nodes.astype('float64') ,\n","                        \"edges\": edges.astype('float64') ,\n","                        \"receivers\": receivers,\n","                        \"senders\": senders\n","                        }\n","  return output_graph\n","\n","def get_output_graph_multiscale_informed(input_graph, output_graph_1, graph_node_list, edge_id_list) :\n","  \"\"\" \n","  Builds sub-graphs using high-fidelity analysis, including the change in attribute relative to the low-fi analysis\n","  18 nodes: [ux, uy, Fx, Fy, du_xx, du_yx, du_xy, du_yy, sig_vonmises,\n","            del_ux, del_uy, del_Fx, del_Fy, del_du_xx, del_du_yx, del_du_xy, del_du_yy, del_sig_vonmises]\n","  17 edges: [del_ux, del_uy, final_length, del_du_xx, del_du_yx, del_du_xy, del_du_yy, del_sig_vonmises,\n","            del_ux, del_uy, del_Fx, del_Fy, del_du_xx, del_du_yx, del_du_xy, del_du_yy, del_sig_vonmises]\n","  \"\"\"\n","  \n","  globals = input_graph[\"globals\"]\n","  senders = input_graph[\"senders\"]\n","  receivers = input_graph[\"receivers\"]\n","\n","  n_nodes = len(input_graph[\"nodes\"][...,0])\n","  nodes = np.zeros((n_nodes, 18))\n","  for i, node in enumerate(graph_node_list) :\n","    nodes[i, ...] = output_graph_1[\"nodes\"][node]\n","\n","  edges = np.zeros((len(senders), 17)) \n","  for i, edge in enumerate(edge_id_list) :\n","    edges[i, ...] = output_graph_1[\"edges\"][edge] \n","\n","  output_graph = {\"globals\": np.asarray(globals).astype('float64') ,\n","                        \"nodes\": nodes.astype('float64') ,\n","                        \"edges\": edges.astype('float64') ,\n","                        \"receivers\": receivers,\n","                        \"senders\": senders\n","                        }\n","  return output_graph"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F-bxCSqn4Tfu"},"source":["# **GraphNetwork Model**\n","Sanchez-Gonzalez, A., Godwin, J., Pfaff, T., Ying, R., Leskovec, J., and Battaglia, P. W., 2020, \"Learning to Simulate Complex Physics with Graph Networks,\" p. arXiv:2002.09405."]},{"cell_type":"code","metadata":{"id":"X3dw07Dt4UL9"},"source":["# Sanchez-Gonzalez, A., Godwin, J., Pfaff, T., Ying, R., Leskovec, J., and Battaglia, P. W., 2020, \n","# \"Learning to Simulate Complex Physics with Graph Networks,\" p. arXiv:2002.09405.\n","\n","import graph_nets as gn\n","import sonnet as snt\n","import tensorflow as tf\n","\n","\n","def build_mlp(\n","    hidden_size: int, num_hidden_layers: int, output_size: int) -> snt.Module:\n","  \"\"\"Builds an MLP.\"\"\"\n","  return snt.nets.MLP(\n","      output_sizes=[hidden_size] * num_hidden_layers + [output_size])\n","\n","\n","class EncodeProcessDecode(snt.AbstractModule):\n","  \"\"\"Encode-Process-Decode function approximator for learnable simulator.\"\"\"\n","\n","  def __init__(\n","      self,\n","      latent_size: int,\n","      mlp_hidden_size: int,\n","      mlp_num_hidden_layers: int,\n","      num_message_passing_steps: int,\n","      output_size: int,\n","      name: str = \"EncodeProcessDecode\"):\n","    \"\"\"Inits the model.\n","    Args:\n","      latent_size: Size of the node and edge latent representations.\n","      mlp_hidden_size: Hidden layer size for all MLPs.\n","      mlp_num_hidden_layers: Number of hidden layers in all MLPs.\n","      num_message_passing_steps: Number of message passing steps.\n","      output_size: Output size of the decode node representations as required\n","        by the downstream update function.\n","      name: Name of the model.\n","    \"\"\"\n","\n","    super().__init__(name=name)\n","\n","    self._latent_size = latent_size\n","    self._mlp_hidden_size = mlp_hidden_size\n","    self._mlp_num_hidden_layers = mlp_num_hidden_layers\n","    self._num_message_passing_steps = num_message_passing_steps\n","    self._output_size = output_size\n","\n","    with self._enter_variable_scope():\n","      self._networks_builder()\n","\n","  def _build(self, input_graph: gn.graphs.GraphsTuple) -> tf.Tensor:\n","    \"\"\"Forward pass of the learnable dynamics model.\"\"\"\n","\n","    # Encode the input_graph.\n","    latent_graph_0 = self._encode(input_graph)\n","\n","    # Do `m` message passing steps in the latent graphs.\n","    latent_graph_m = self._process(latent_graph_0)\n","\n","    # Decode from the last latent graph.\n","    return self._decode(latent_graph_m)\n","\n","  def _networks_builder(self):\n","    \"\"\"Builds the networks.\"\"\"\n","\n","    def build_mlp_with_layer_norm():\n","      mlp = build_mlp(\n","          hidden_size=self._mlp_hidden_size,\n","          num_hidden_layers=self._mlp_num_hidden_layers,\n","          output_size=self._latent_size)\n","      return snt.Sequential([mlp, snt.LayerNorm()])\n","\n","    # The encoder graph network independently encodes edge and node features.\n","    encoder_kwargs = dict(\n","        edge_model_fn=build_mlp_with_layer_norm,\n","        node_model_fn=build_mlp_with_layer_norm)\n","    self._encoder_network = gn.modules.GraphIndependent(**encoder_kwargs)\n","\n","    # Create `num_message_passing_steps` graph networks with unshared parameters\n","    # that update the node and edge latent features.\n","    # Note that we can use `modules.InteractionNetwork` because\n","    # it also outputs the messages as updated edge latent features.\n","    self._processor_networks = []\n","    for _ in range(self._num_message_passing_steps):\n","      self._processor_networks.append(\n","          gn.modules.InteractionNetwork(\n","              edge_model_fn=build_mlp_with_layer_norm,\n","              node_model_fn=build_mlp_with_layer_norm))\n","\n","    # The decoder MLP decodes node latent features into the output size.\n","    self._decoder_network = build_mlp(\n","        hidden_size=self._mlp_hidden_size,\n","        num_hidden_layers=self._mlp_num_hidden_layers,\n","        output_size=self._output_size)\n","\n","  def _encode(\n","      self, input_graph: gn.graphs.GraphsTuple) -> gn.graphs.GraphsTuple:\n","    \"\"\"Encodes the input graph features into a latent graph.\"\"\"\n","\n","    # Copy the globals to all of the nodes, if applicable.\n","    if input_graph.globals is not None:\n","      broadcasted_globals = gn.blocks.broadcast_globals_to_nodes(input_graph)\n","      input_graph = input_graph.replace(\n","          nodes=tf.concat([input_graph.nodes, broadcasted_globals], axis=-1),\n","          globals=None)\n","\n","    # Encode the node and edge features.\n","    latent_graph_0 = self._encoder_network(input_graph)\n","    return latent_graph_0\n","\n","  def _process(\n","      self, latent_graph_0: gn.graphs.GraphsTuple) -> gn.graphs.GraphsTuple:\n","    \"\"\"Processes the latent graph with several steps of message passing.\"\"\"\n","\n","    # Do `m` message passing steps in the latent graphs.\n","    # (In the shared parameters case, just reuse the same `processor_network`)\n","    latent_graph_prev_k = latent_graph_0\n","    for processor_network_k in self._processor_networks:\n","      latent_graph_k = self._process_step(\n","          processor_network_k, latent_graph_prev_k)\n","      latent_graph_prev_k = latent_graph_k\n","\n","    latent_graph_m = latent_graph_k\n","    return latent_graph_m\n","\n","  def _process_step(\n","      self, processor_network_k: snt.Module,\n","      latent_graph_prev_k: gn.graphs.GraphsTuple) -> gn.graphs.GraphsTuple:\n","    \"\"\"Single step of message passing with node/edge residual connections.\"\"\"\n","\n","    # One step of message passing.\n","    latent_graph_k = processor_network_k(latent_graph_prev_k)\n","\n","    # Add residuals.\n","    latent_graph_k = latent_graph_k.replace(\n","        nodes=latent_graph_k.nodes+latent_graph_prev_k.nodes,\n","        edges=latent_graph_k.edges+latent_graph_prev_k.edges)\n","    return latent_graph_k\n","\n","  def _decode(self, latent_graph: gn.graphs.GraphsTuple) -> tf.Tensor:\n","    \"\"\"Decodes from the latent graph.\"\"\"\n","    return self._decoder_network(latent_graph.nodes), self._decoder_network(latent_graph.edges)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NP_7griL3SdJ"},"source":["# **GraphNets Functions**"]},{"cell_type":"markdown","metadata":{"id":"MHmyjT0TDuUf"},"source":["## Build Data from Graph Dicts"]},{"cell_type":"code","metadata":{"id":"DNVxXyVkDvqR"},"source":["def generate_raw_graph_tuple(input_graph_list, simulated_graph_list):\n","      \"\"\"\n","      Processes graph_dicts into graphtuples\n","      \"\"\"\n","      input_gt_list = []\n","      sim_gt_list = []\n","      for input_g in input_graph_list :\n","          input_gt = utils_tf.data_dicts_to_graphs_tuple([input_g])\n","          input_gt_list.append(input_gt)\n","      for sim_g in simulated_graph_list :\n","          sim_gt = utils_tf.data_dicts_to_graphs_tuple([sim_g])\n","          sim_gt_list.append(sim_gt)\n","          \n","      return input_gt_list, sim_gt_list\n","\n","\n","def generate_batched_graph_tuple(input_gt_list, sim_gt_list,\n","                                batch_size):\n","    \"\"\"\n","    Concatenates the input graphtuples to create fixed batches\n","    \"\"\"\n","    input_batch_list = []\n","    sim_batch_list = []\n","      \n","    for i in range(0, len(input_gt_list), batch_size - 1) :\n","        input_batch = input_gt_list[i]\n","        sim_batch = sim_gt_list[i]\n","        if batch_size > 1 :\n","            for j in range(i + 1, i + batch_size - 1) :\n","                input_0 = input_batch\n","                input_1 = input_gt_list[j]\n","                input_batch = (utils_tf.concat([input_0, input_1], axis = 0))\n","\n","                sim_0 = sim_batch\n","                sim_1 = sim_gt_list[j]\n","                sim_batch = (utils_tf.concat([sim_0, sim_1], axis = 0))\n","        \n","        input_batch_list.append(input_batch)\n","        sim_batch_list.append(sim_batch)\n","    \n","    return input_batch_list, sim_batch_list\n","\n","def generate_raw_data(input_graph_list, simulated_graph_list, batch_size) :\n","  \"\"\"\n","  Generate raw graphtuple lists, no normalization\n","  \"\"\"\n","  input_gt_list_tr, simulated_gt_list_tr  = generate_raw_graph_tuple(input_graph_list, simulated_graph_list)\n","  initial_conditions_tr, true_deformation_tr  = generate_batched_graph_tuple(input_gt_list_tr, simulated_gt_list_tr,\n","                                                                            batch_size_tr + 1)\n","  return initial_conditions_tr, true_deformation_tr\n","\n","def build_input_graph_list_mixedBC(data_size, m1_min_max, m2_min_max, coord_noise_min_max, refine_min_max, vol_frac_min_max) :\n","    \"\"\"\n","    Generates random mesh inputs\n","    \"\"\"\n","    m1_list = []\n","    m2_list = []\n","    coord_noise_list = []\n","    refine_list = []\n","    vol_frac_list = []\n","    for i in range(data_size) :\n","      coord_noise_list.append(np.random.uniform(coord_noise_min_max[0], coord_noise_min_max[1]))\n","      m1_list.append(2*(np.random.randint(m1_min_max[0], m1_min_max[1])//2))\n","      m2_list.append(2*(np.random.randint(m2_min_max[0], m2_min_max[1])//2))\n","      refine_list.append((np.random.uniform(refine_min_max[0], refine_min_max[1])) )\n","      vol_frac_list.append((np.random.uniform(vol_frac_min_max[0], vol_frac_min_max[1])) )\n","        \n","    return m1_list, m2_list, coord_noise_list, refine_list, vol_frac_list\n","\n","def generate_data(data_size, m1_min_max, m2_min_max, refine_min_max, vol_frac_min_max, density_min_max, \n","                             noise_type, coord_noise_min_max, support_options, force_options, \n","                       multi_fidelity_opt, KUR_opt, random_bound_opt, random_force_opt,\n","                         elem_type, base_bound_x, base_bound_y, E, v, applied_force_vals, force_dofs, body_force, multiscale_min_max_m1, multiscale_min_max_m2, force_scale,\n","                         scale_projection = True) :\n","  \"\"\"\n","  Applies randomization to input, then simulates deformation, \n","  returns lists of graph dicts via FEA\n","  \"\"\"\n","  efficient_opt = KUR_opt \n","  m1_list, m2_list, coord_noise_list, refine_list, vol_frac_list = build_input_graph_list_mixedBC(\n","      data_size, m1_min_max, m2_min_max, coord_noise_min_max, refine_min_max, vol_frac_min_max)\n","  raw_list = []\n","  input_graph_list = []\n","  simulated_graph_list = []\n","  recovery_structures = []\n","  for M1, M2, coord_noise, refine_fract, vol_frac in zip(m1_list, m2_list, coord_noise_list, refine_list, vol_frac_list) :\n","    \n","    # INIT\n","    if random_bound_opt :\n","      bound_x = [val*np.random.uniform(0.5, 2.) for val in list(base_bound_x)]\n","      bound_y_fact = np.random.uniform(0.5, 2.)\n","      bound_y = [val*bound_y_fact for val in list(base_bound_y)]\n","      bound_x = [round(val, 1) for val in bound_x]\n","      bound_y = [round(val, 1) for val in bound_y]\n","\n","    else :\n","      bound_x, bound_y = base_bound_x, base_bound_y\n","\n","    if random_force_opt :\n","      force_vals = [val*np.random.choice([-1,0,1]) for val in applied_force_vals]\n","      while (force_vals[0] == 0) and (force_vals[1] == 0) :\n","        force_vals = [val*np.random.choice([-1,0,1]) for val in applied_force_vals]\n","    else :\n","      force_vals = applied_force_vals\n","\n","    support_option = np.random.choice(support_options)\n","    if support_option == \"MBB\" or support_option == \"dual_cantilever\" :\n","      force_option = np.random.choice([\"top_distributed\"])\n","      mesh_builder = build_mesh\n","      mesh_processor = dual_mesh_pre_process\n","    elif support_option == \"L_bracket\" :\n","      force_option = \"side_center\"\n","      mesh_builder = build_mesh_L_bracket\n","      mesh_processor = dual_mesh_pre_process_L_bracket\n","    else :\n","      force_option = np.random.choice(force_options)\n","      mesh_builder = build_mesh\n","      mesh_processor = dual_mesh_pre_process\n","      \n","    # SUB-DOMAIN INIT  \n","    mesh_0 = mesh_builder(elem_type, M1, M2, bound_x, bound_y,\n","                  \"posi\", 0.0, refine_fract)\n","    element_density_0 = [1]*mesh_0.n_elem\n","    surf_nodes_0  = [1]*mesh_0.n_node\n","    void_nodes_0  = [1]*mesh_0.n_node\n","    base_material_0 = assign_material(elem_type, mesh_0, E, v, element_density_0)\n","    bc_0 = assign_BC_option(mesh_0, force_vals, force_dofs, body_force,\n","                     support_option, force_option)\n","    fea_0 = assemble_matrices(elem_type, mesh_0, base_material_0, bc_0, efficient_opt)\n","    results_0 = solve_FEA(mesh_0, bc_0, fea_0)\n","    nodal_stress_0, elem_stress_0 = get_stress_gauss(elem_type, mesh_0, base_material_0, results_0)\n","    nodal_du_0, elem_du = get_dU_gauss(elem_type, mesh_0, results_0.UUR.T )\n","    input_graph_0 = get_input_graph(elem_type, mesh_0, bc_0, element_density_0, surf_nodes_0, void_nodes_0)\n","    output_graph_0 = get_output_graph(elem_type, input_graph_0, mesh_0, results_0, nodal_stress_0, nodal_du_0)\n","\n","    # LOW-FIDELITY FEA\n","    if multi_fidelity_opt and scale_projection:\n","      m1_p = M1*np.random.randint(multiscale_min_max_m1[0], 1+multiscale_min_max_m1[1]//2)\n","      m2_p = M2*np.random.randint(multiscale_min_max_m2[0], 1+multiscale_min_max_m2[1]//2)\n","    elif multi_fidelity_opt and not scale_projection:\n","      m1_p = M1*2\n","      m2_p = M2*2\n","    else :\n","      m1_p, m2_p = M1, M2\n","    mesh_p = mesh_builder(elem_type, m1_p, m2_p, bound_x, bound_y,\n","                      \"posi\", 0.0, refine_fract)\n","    element_density_p = [1]*mesh_p.n_elem\n","    surf_nodes_p  = [1]*mesh_p.n_node\n","    void_nodes_p  = [1]*mesh_p.n_node\n","    base_material_p = assign_material(elem_type, mesh_p, E, v, element_density_p)\n","    bc_p = assign_BC_option(mesh_p, force_vals, force_dofs, body_force, support_option, force_option)\n","    fea_p = assemble_matrices(elem_type, mesh_p, base_material_p, bc_p, efficient_opt)\n","    results_p = solve_FEA(mesh_p, bc_p, fea_p)\n","    nodal_stress_p, elem_stress_p = get_stress_gauss(elem_type, mesh_p, base_material_p, results_p)\n","    nodal_du_p, elem_du = get_dU_gauss(elem_type, mesh_p, results_p.UUR.T )\n","\n","\n","    # HIGH-FIDELITY FEA\n","    if scale_projection :\n","      m1 = m1_p*np.random.randint(multiscale_min_max_m1[0], multiscale_min_max_m1[1])\n","      m2 = m2_p*np.random.randint(multiscale_min_max_m2[0], multiscale_min_max_m2[1])\n","    else :\n","      m1 = m1_p*np.random.randint(multiscale_min_max_m1[0], multiscale_min_max_m1[1])//2\n","      m2 = m2_p*np.random.randint(multiscale_min_max_m2[0], multiscale_min_max_m2[1])//2\n","    print(\"\\nStat mesh: {} x {}\".format(M1, M2), end = \" || \")\n","    print(\"Father mesh: {} x {}\".format(m1_p, m2_p), end = \" || \")\n","    print(\"Child mesh: {} x {}\".format(m1, m2), end = \" || \")\n","    print(\"Force Vals: {:.4f}, {:.4f}\".format(force_vals[0], force_vals[1]), end = \" || \")\n","    print(\"{}, {}\".format(support_option , force_option), end = \" || \")\n","    print(bound_x, \"x\",  bound_y)\n","    mesh_1 = mesh_builder(elem_type, m1, m2, bound_x, bound_y,\n","                      \"posi\", 0.0, refine_fract)\n","    base_coords = copy.deepcopy(mesh_1.coords)\n","    if coord_noise > 0 or noise_type == \"row\" :\n","      mesh_1.coords = noise_mesh_MS(noise_type, coord_noise, mesh_0, mesh_1)\n","    else :\n","      print(\"WARNING: NO mesh noise\")\n","    element_density_1 = [1]*mesh_1.n_elem\n","    base_density_1 = [1]*mesh_1.n_elem\n","    surf_nodes_1  = [1]*mesh_1.n_node\n","    void_nodes_1  = [1]*mesh_1.n_node\n","    base_material_1 = assign_material(elem_type, mesh_1, E, v, element_density_1)\n","    bc_1 = assign_BC_option(mesh_1, force_vals, force_dofs, body_force,\n","                     support_option, force_option)\n","    fea_1 = assemble_matrices(elem_type, mesh_1, base_material_1, bc_1, efficient_opt)\n","    results_1 = solve_FEA(mesh_1, bc_1, fea_1)\n","    nodal_stress_1, elem_stress_1 = get_stress_gauss(elem_type, mesh_1, base_material_1, results_1)\n","    nodal_du_1, _ = get_dU_gauss(elem_type, mesh_1, results_1.UUR.T )\n","\n","    # BUILD GLOBAL GRAPHS\n","    father_elems_0, graph_nodes_0 = mesh_processor(mesh_0, mesh_1)\n","    father_elems, graph_nodes = mesh_processor(mesh_p, mesh_1)\n","\n","    input_graph_0 = get_input_graph(elem_type, mesh_0, bc_0, element_density_0, surf_nodes_0, void_nodes_0)\n","    output_graph_0 = get_output_graph(elem_type, input_graph_0, mesh_0, results_0, nodal_stress_0, nodal_du_0)\n","\n","    input_graph_p = get_input_graph(elem_type, mesh_p, bc_p, element_density_p, surf_nodes_p, void_nodes_p)\n","    output_graph_p = get_output_graph(elem_type, input_graph_p, mesh_p, results_p, nodal_stress_p, nodal_du_p)\n","\n","    input_graph_1 = get_input_graph_dual_informed(elem_type, mesh_1, bc_1, element_density_1, surf_nodes_1, void_nodes_1,\n","                                father_elems_0, father_elems, graph_nodes,\n","                                mesh_p, output_graph_p) \n","    output_graph_1 = get_output_graph_informed(elem_type, input_graph_1, mesh_1, results_1, nodal_stress_1, nodal_du_1)\n","\n","    err_projection, avg_err_tst, max_tst, min_tst = get_disp_err(results_1.UUR.T, input_graph_1[\"nodes\"][..., 10:12])\n","    print(\"Projection Error: avg {:.4f}, max {:.4f}, min {:.4f}\".format(avg_err_tst, max_tst, min_tst))\n","\n"," \n","    # CHECK FOR ERRORS\n","    z0 = np.asarray(results_1.UUR.T[..., 0])\n","    z1 = np.asarray(results_1.UUR.T[..., 1])\n","    double_check = np.maximum(np.amax(np.abs(z0)), np.amax(np.abs(z0)))\n","    if double_check > 0.1 or double_check == 0:\n","      print(\"FATAL ERROR, GARBAGE PRODUCED\",double_check)\n","    else :\n","      print(\"Pass: \",double_check)\n","    \n","    # x, y = np.asarray(mesh_1.coords).T\n","    # plot_nodal_vect(x, y, z0, \" \", 4e2)\n","    # plot_nodal_vect(x, y, z1, \" \", 4e2)\n","    # plot_mesh(elem_type, False, \" \", bound_x, bound_y,\n","    #           mesh_1, bc_1, results_1.UUR, elem_stress_1.T[-1,...])\n","\n","    # RETURN\n","    if multi_fidelity_opt : \n","      input_sub_graph_list = []\n","      output_sub_graph_list = []\n","      graph_edges = []\n","      for elem in range(mesh_0.n_elem) :\n","        graph_node_list = graph_nodes_0[elem]\n","        father_elem_node_list = father_elems_0[elem]\n","\n","        ig, edge_id_list = get_input_graph_multiscale_informed(elem, input_graph_0, input_graph_1, output_graph_0, output_graph_1, \n","                                                              graph_node_list, father_elem_node_list, mesh_0)\n","        og = get_output_graph_multiscale_informed(ig, output_graph_1, graph_node_list, edge_id_list)\n","\n","        graph_edges.append(edge_id_list)\n","        input_sub_graph_list.append(ig)\n","        output_sub_graph_list.append(og)\n","      \n","      recovery_structures.append((output_sub_graph_list, graph_nodes_0, graph_edges, input_graph_0, output_graph_0, input_graph_1, output_graph_1))\n","      input_graph_list += input_sub_graph_list\n","      simulated_graph_list += output_sub_graph_list\n","      raw_list.append([mesh_1, bc_1, base_material_1, fea_1, results_1])\n","    \n","    else :\n","      recovery_structures.append((input_graph_0, output_graph_0, input_graph_1, output_graph_1, fea_1.KUR))\n","      raw_list.append([mesh_1, bc_1, base_material_1, fea_1, results_1])\n","      input_graph_list.append(input_graph_1)\n","      simulated_graph_list.append(output_graph_1)\n","\n","\n","  return raw_list, input_graph_list, simulated_graph_list, recovery_structures\n","\n","def generate_convergence_data(M1_list, M2_list, m1p_list, m2p_list, m1_list, m2_list, refine_min_max, vol_frac_min_max, density_min_max, \n","                             noise_type, coord_noise_min_max, support_options, force_options, \n","                       multi_fidelity_opt, KUR_opt, random_bound_opt, random_force_opt,\n","                         elem_type, base_bound_x, base_bound_y, E, v, applied_force_vals, force_dofs, body_force, multiscale_min_max_m1, multiscale_min_max_m2, force_scale,\n","                         hole_radius = 0.0) :\n","  \"\"\"\n","  Applies randomization to input, then simulates deformation, \n","  returns lists of graph dicts via FEA\n","  \"\"\"\n","  efficient_opt = KUR_opt \n","  data_size = len(M1_list)\n","  m1_min_max, m2_min_max = (12,13), (6,7)\n","  _, _, coord_noise_list, refine_list, vol_frac_list = build_input_graph_list_mixedBC(\n","      data_size, m1_min_max, m2_min_max, coord_noise_min_max, refine_min_max, vol_frac_min_max)\n","  raw_list = []\n","  input_graph_list = []\n","  simulated_graph_list = []\n","  recovery_structures = []\n","  for i, (M1, M2, coord_noise, refine_fract, vol_frac) in enumerate(zip(M1_list, M2_list, coord_noise_list, refine_list, vol_frac_list)) :\n","    \n","    # INIT\n","    if random_bound_opt :\n","      bound_x = [val*np.random.uniform(0.5, 2.) for val in list(base_bound_x)]\n","      bound_y_fact = np.random.uniform(0.5, 2.)\n","      bound_y = [val*bound_y_fact for val in list(base_bound_y)]\n","      bound_x = [round(val, 1) for val in bound_x]\n","      bound_y = [round(val, 1) for val in bound_y]\n","\n","    else :\n","      bound_x, bound_y = base_bound_x, base_bound_y\n","\n","    if random_force_opt :\n","      force_vals = [val*np.random.choice([-1,0,1]) for val in applied_force_vals]\n","      while (force_vals[0] == 0) and (force_vals[1] == 0) :\n","        force_vals = [val*np.random.choice([-1,0,1]) for val in applied_force_vals]\n","    else :\n","      force_vals = applied_force_vals\n","\n","    support_option = np.random.choice(support_options)\n","    if support_option == \"MBB\" or support_option == \"dual_cantilever\" :\n","      force_option = np.random.choice([\"top_distributed\"])\n","      mesh_builder = build_mesh\n","      mesh_processor = dual_mesh_pre_process\n","    elif support_option == \"L_bracket\" :\n","      force_option = \"side_center\"\n","      mesh_builder = build_mesh_L_bracket\n","      mesh_processor = dual_mesh_pre_process_L_bracket\n","    else :\n","      force_option = np.random.choice(force_options)\n","      mesh_builder = build_mesh\n","      mesh_processor = dual_mesh_pre_process\n","\n","    m1_p, m2_p = m1p_list[i], m2p_list[i]\n","    m1, m2 =  m1_list[i], m2_list[i]\n","    print(\"\\nStat mesh: {} x {}\".format(M1, M2), end = \" || \")\n","    print(\"Father mesh: {} x {}\".format(m1_p, m2_p), end = \" || \")\n","    print(\"Child mesh: {} x {}\".format(m1, m2), end = \" || \")\n","    print(\"Force Vals: {:.4f}, {:.4f}\".format(force_vals[0], force_vals[1]), end = \" || \")\n","    print(\"{}, {}\".format(support_option , force_option), end = \" || \")\n","    print(bound_x, \"x\",  bound_y)\n","    \n","    if hole_radius != 0 :\n","      mesh_builder = build_mesh_hole\n","      mesh_0, element_density_0 = mesh_builder(elem_type, M1, M2, bound_x, bound_y,\n","                  \"posi\", 0.0, refine_fract, radius=hole_radius)\n","      mesh_p, element_density_p = mesh_builder(elem_type, m1_p, m2_p, bound_x, bound_y,\n","                      \"posi\", 0.0, refine_fract, radius=hole_radius)\n","      mesh_1, element_density_1 = mesh_builder(elem_type, m1, m2, bound_x, bound_y,\n","                      \"posi\", 0.0, refine_fract, radius=hole_radius)\n","    else :\n","      mesh_0 = mesh_builder(elem_type, M1, M2, bound_x, bound_y,\n","                  \"posi\", 0.0, refine_fract)\n","      element_density_0 = [1]*mesh_0.n_elem\n","      mesh_p = mesh_builder(elem_type, m1_p, m2_p, bound_x, bound_y,\n","                      \"posi\", 0.0, refine_fract)\n","      element_density_p = [1]*mesh_p.n_elem\n","      mesh_1 = mesh_builder(elem_type, m1, m2, bound_x, bound_y,\n","                      \"posi\", 0.0, refine_fract)\n","      element_density_1 = [1]*mesh_1.n_elem\n","\n","    # SUB-DOMAIN INIT  \n","    surf_nodes_0  = [1]*mesh_0.n_node\n","    void_nodes_0  = [1]*mesh_0.n_node\n","    base_material_0 = assign_material(elem_type, mesh_0, E, v, element_density_0)\n","    bc_0 = assign_BC_option(mesh_0, force_vals, force_dofs, body_force,\n","                     support_option, force_option)\n","    fea_0 = assemble_matrices(elem_type, mesh_0, base_material_0, bc_0, efficient_opt)\n","    results_0 = solve_FEA(mesh_0, bc_0, fea_0)\n","    nodal_stress_0, elem_stress_0 = get_stress_gauss(elem_type, mesh_0, base_material_0, results_0)\n","    nodal_du_0, elem_du = get_dU_gauss(elem_type, mesh_0, results_0.UUR.T )\n","    input_graph_0 = get_input_graph(elem_type, mesh_0, bc_0, element_density_0, surf_nodes_0, void_nodes_0)\n","    output_graph_0 = get_output_graph(elem_type, input_graph_0, mesh_0, results_0, nodal_stress_0, nodal_du_0)\n","\n","    # LOW-FIDELITY FEA\n","    surf_nodes_p  = [1]*mesh_p.n_node\n","    void_nodes_p  = [1]*mesh_p.n_node\n","    base_material_p = assign_material(elem_type, mesh_p, E, v, element_density_p)\n","    bc_p = assign_BC_option(mesh_p, force_vals, force_dofs, body_force, support_option, force_option)\n","    fea_p = assemble_matrices(elem_type, mesh_p, base_material_p, bc_p, efficient_opt)\n","    results_p = solve_FEA(mesh_p, bc_p, fea_p)\n","    nodal_stress_p, elem_stress_p = get_stress_gauss(elem_type, mesh_p, base_material_p, results_p)\n","    nodal_du_p, elem_du = get_dU_gauss(elem_type, mesh_p, results_p.UUR.T )\n","\n","\n","    # HIGH-FIDELITY FEA\n","    base_coords = copy.deepcopy(mesh_1.coords)\n","    if coord_noise > 0 or noise_type == \"row\" :\n","      mesh_1.coords = noise_mesh_MS(noise_type, coord_noise, mesh_0, mesh_1)\n","    else :\n","      print(\"WARNING: NO mesh noise\")\n","    base_density_1 = [1]*mesh_1.n_elem\n","    surf_nodes_1  = [1]*mesh_1.n_node\n","    void_nodes_1  = [1]*mesh_1.n_node\n","    base_material_1 = assign_material(elem_type, mesh_1, E, v, element_density_1)\n","    bc_1 = assign_BC_option(mesh_1, force_vals, force_dofs, body_force,\n","                     support_option, force_option)\n","    fea_1 = assemble_matrices(elem_type, mesh_1, base_material_1, bc_1, efficient_opt)\n","    results_1 = solve_FEA(mesh_1, bc_1, fea_1)\n","    nodal_stress_1, elem_stress_1 = get_stress_gauss(elem_type, mesh_1, base_material_1, results_1)\n","    nodal_du_1, _ = get_dU_gauss(elem_type, mesh_1, results_1.UUR.T )\n","\n","    # BUILD GLOBAL GRAPHS\n","    father_elems_0, graph_nodes_0 = mesh_processor(mesh_0, mesh_1)\n","    father_elems, graph_nodes = mesh_processor(mesh_p, mesh_1)\n","\n","    input_graph_0 = get_input_graph(elem_type, mesh_0, bc_0, element_density_0, surf_nodes_0, void_nodes_0)\n","    output_graph_0 = get_output_graph(elem_type, input_graph_0, mesh_0, results_0, nodal_stress_0, nodal_du_0)\n","\n","    input_graph_p = get_input_graph(elem_type, mesh_p, bc_p, element_density_p, surf_nodes_p, void_nodes_p)\n","    output_graph_p = get_output_graph(elem_type, input_graph_p, mesh_p, results_p, nodal_stress_p, nodal_du_p)\n","\n","    input_graph_1 = get_input_graph_dual_informed(elem_type, mesh_1, bc_1, element_density_1, surf_nodes_1, void_nodes_1,\n","                                father_elems_0, father_elems, graph_nodes,\n","                                mesh_p, output_graph_p) \n","    output_graph_1 = get_output_graph_informed(elem_type, input_graph_1, mesh_1, results_1, nodal_stress_1, nodal_du_1)\n","\n","    err_projection, avg_err_tst, max_tst, min_tst = get_disp_err(results_1.UUR.T, input_graph_1[\"nodes\"][..., 10:12])\n","    print(\"Projection Error: avg {:.4f}, max {:.4f}, min {:.4f}\".format(avg_err_tst, max_tst, min_tst))\n","\n"," \n","    # CHECK FOR ERRORS\n","    z0 = np.asarray(results_1.UUR.T[..., 0])\n","    z1 = np.asarray(results_1.UUR.T[..., 1])\n","    double_check = np.maximum(np.amax(np.abs(z0)), np.amax(np.abs(z0)))\n","    if double_check > 0.1 or double_check == 0:\n","      print(\"FATAL ERROR, GARBAGE PRODUCED\",double_check)\n","    else :\n","      print(\"Pass: \",double_check)\n","    \n","    # x, y = np.asarray(mesh_1.coords).T\n","    # plot_nodal_vect(x, y, z0, \" \", 4e2)\n","    # plot_nodal_vect(x, y, z1, \" \", 4e2)\n","    # plot_mesh(elem_type, False, \" \", bound_x, bound_y,\n","    #           mesh_1, bc_1, results_1.UUR, elem_stress_1.T[-1,...])\n","\n","    # RETURN\n","    if multi_fidelity_opt : \n","      input_sub_graph_list = []\n","      output_sub_graph_list = []\n","      graph_edges = []\n","      for elem in range(mesh_0.n_elem) :\n","        graph_node_list = graph_nodes_0[elem]\n","        father_elem_node_list = father_elems_0[elem]\n","\n","        ig, edge_id_list = get_input_graph_multiscale_informed(elem, input_graph_0, input_graph_1, output_graph_0, output_graph_1, \n","                                                              graph_node_list, father_elem_node_list, mesh_0)\n","        og = get_output_graph_multiscale_informed(ig, output_graph_1, graph_node_list, edge_id_list)\n","\n","        graph_edges.append(edge_id_list)\n","        input_sub_graph_list.append(ig)\n","        output_sub_graph_list.append(og)\n","      \n","      recovery_structures.append((output_sub_graph_list, graph_nodes_0, graph_edges, input_graph_0, output_graph_0, input_graph_1, output_graph_1))\n","      input_graph_list += input_sub_graph_list\n","      simulated_graph_list += output_sub_graph_list\n","      raw_list.append([mesh_1, bc_1, base_material_1, fea_1, results_1])\n","    \n","    else :\n","      recovery_structures.append((input_graph_0, output_graph_0, input_graph_1, output_graph_1, fea_1.KUR))\n","      raw_list.append([mesh_1, bc_1, base_material_1, fea_1, results_1])\n","      input_graph_list.append(input_graph_1)\n","      simulated_graph_list.append(output_graph_1)\n","\n","\n","  return raw_list, input_graph_list, simulated_graph_list, recovery_structures"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jv9QRft9kZUL"},"source":["## Standardization"]},{"cell_type":"code","metadata":{"id":"SwfrDXerkbmE"},"source":["def fetch_stats(complete_dirname) :\n","  \"\"\"\n","  load stats in from a saved list of graph_tuples\n","  \"\"\"\n","  node_count = 0\n","  edge_count = 0\n","\n","  item = []\n","  for load_idx in range(10) :\n","    with open('{}{}'.format(complete_dirname, load_idx), 'rb') as f :\n","      item += dill.load(f)\n","\n","  # MEANS\n","  load_idx = 0\n","  for i, gt in enumerate(item) :\n","    if (load_idx == 0) and (i == 0) :\n","      node_sum = np.sum(gt.nodes, axis = 0)\n","      edge_sum = np.sum(gt.edges, axis = 0)\n","    else :\n","      node_sum += np.sum(gt.nodes, axis = 0)\n","      edge_sum += np.sum(gt.edges, axis = 0)\n","    node_count += gt.n_node\n","    edge_count += gt.n_edge\n","  node_means = node_sum / node_count\n","  edge_means = edge_sum / edge_count\n","\n","  # STD DEVS\n","  for i, gt in enumerate(item) :\n","    if (load_idx == 0) and (i == 0) :\n","      node_sum = np.sum((gt.nodes - node_means)**2, axis = 0)\n","      edge_sum = np.sum((gt.edges - edge_means)**2, axis = 0)\n","    else :\n","      node_sum += np.sum((gt.nodes - node_means)**2, axis = 0)\n","      edge_sum += np.sum((gt.edges - edge_means)**2, axis = 0)\n","  node_stds = (node_sum / node_count)**0.5\n","  edge_stds = (edge_sum / edge_count)**0.5\n","\n","  return node_means, node_stds, edge_means, edge_stds\n","\n","def normalize_input_list_informed_multiscale(input_list, mean_list, std_list) :\n","\n","  mean_array = np.asarray(mean_list)\n","  std_array = np.asarray(std_list)\n","\n","  local_mean_list = []\n","  local_std_list = []\n","  new_edge_list = []\n","  local_edge_mean_list = []\n","  local_edge_std_list = []\n","  for input_gt in input_list :\n","    # USE GLOBAL STATS\n","    input_gt[\"nodes\"][..., 0:2] = np.divide(np.subtract(input_gt[\"nodes\"][..., 0:2],  \n","                                                      mean_array[0:2]), std_array[0:2]) \n","    input_gt[\"edges\"][..., 0:5] = np.divide(np.subtract(input_gt[\"edges\"][..., 0:5],  \n","                                                      mean_array[2:7]), std_array[2:7])\n","\n","    # COLLECT LOCAL STATS\n","    # father_means = np.max(input_gt[\"nodes\"][..., 10:19], axis = 0) #np.mean\n","    # father_stds = np.min(input_gt[\"nodes\"][..., 10:19], axis = 0) # np.std\n","    # father_edge_means = np.max(input_gt[\"edges\"][..., 7:16], axis = 0)\n","    # father_edge_stds = np.min(input_gt[\"edges\"][..., 7:16], axis = 0)\n","    father_means = np.mean(input_gt[\"nodes\"][..., 10:19], axis = 0) \n","    father_stds = np.std(input_gt[\"nodes\"][..., 10:19], axis = 0) \n","    father_edge_means = np.mean(input_gt[\"edges\"][..., 7:16], axis = 0)\n","    father_edge_stds = np.std(input_gt[\"edges\"][..., 7:16], axis = 0)\n","    local_mean_list.append(father_means)\n","    local_std_list.append(father_stds)\n","    local_edge_mean_list.append(father_edge_means)\n","    local_edge_std_list.append(father_edge_stds)\n","    \n","    # LOCAL NORMALIZATION\n","    for i in range(len(input_gt[\"nodes\"][..., 0])) :\n","        # input_gt[\"nodes\"][i, 10:12] = -0.5 +  np.divide(np.subtract(input_gt[\"nodes\"][i, 10:12],  \n","        #                                                   father_stds[0:2]), (father_means[0:2] - father_stds[0:2]) )\n","        # input_gt[\"nodes\"][i, 14:19] = -0.5 + np.divide(np.subtract(input_gt[\"nodes\"][i, 14:19],  \n","        #                                                   father_stds[4:9]), father_means[4:9] - father_stds[4:9]) \n","        input_gt[\"nodes\"][i, 10:12] = np.divide(np.subtract(input_gt[\"nodes\"][i, 10:12],  \n","                                                          father_means[0:2]), father_stds[0:2]) \n","        input_gt[\"nodes\"][i, 14:19] = np.divide(np.subtract(input_gt[\"nodes\"][i, 14:19],  \n","                                                          father_means[4:9]), father_stds[4:9]) \n","\n","    for i in range(len(input_gt[\"edges\"][..., 0])) :\n","        input_gt[\"edges\"][i, 7:9] = -0.5 + np.divide(np.subtract(input_gt[\"edges\"][i, 7:9],  \n","                                                          father_edge_stds[0:2]), father_edge_means[0:2] - father_edge_stds[0:2]) \n","        input_gt[\"edges\"][i, 11:16] = -0.5 + np.divide(np.subtract(input_gt[\"edges\"][i, 11:16],  \n","                                                  father_edge_stds[4:9]), father_edge_means[4:9] -  father_edge_stds[4:9]) \n","        # input_gt[\"edges\"][i, 7:9] = np.divide(np.subtract(input_gt[\"edges\"][i, 7:9],  \n","        #                                                   father_edge_means[0:2]), father_edge_stds[0:2]) \n","        # input_gt[\"edges\"][i, 11:16] = np.divide(np.subtract(input_gt[\"edges\"][i, 11:16],  \n","        #                                           father_edge_means[4:9]), father_edge_stds[4:9]) \n","\n","  \n","  return input_list, local_mean_list, local_std_list, local_edge_mean_list, local_edge_std_list\n","\n","def local_standard_target(target_graph_list, local_means, local_stds) :\n","\n","  for idx, target in enumerate(target_graph_list) :\n","    # LOCAL NORMALIZATION\n","    for i in range(len(target[\"nodes\"][..., 0])) :\n","      # target[\"nodes\"][i, 0:2] = -0.5 + (target[\"nodes\"][i, 0:2] - local_stds[idx][0:2])/ (local_means[idx][0:2] - local_stds[idx][0:2])\n","      target[\"nodes\"][i, 0:2] = (target[\"nodes\"][i, 0:2] - local_means[idx][0:2])/ (local_stds[idx][0:2])\n","  return target_graph_list"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TFRNmw5pD8kS"},"source":["## Error and Processing from GN"]},{"cell_type":"code","metadata":{"id":"J6n8GUWw3RLI"},"source":["def get_disp_err(s, m) :\n","  \"\"\" \n","  Inputs : simulated UUR, modeled UUR as [N_NODE X 2]\n","  Returns : Nodal displacement error, avg, max, min\n","  \"\"\"\n","  err = []\n","  err_abs = []\n","  for i in range(len(m)) :\n","      disp_s = (s[i][0]**2 + s[i][1]**2)**0.5\n","      disp_m = (m[i][0]**2 + m[i][1]**2)**0.5\n","      if disp_s != 0 :\n","          err.append((((disp_m - disp_s)/disp_s)))\n","          err_abs.append((((disp_m - disp_s)/disp_s)**2)**0.5)\n","      else :\n","          err.append((((disp_m - disp_s))))\n","          err_abs.append((((disp_m - disp_s))**2)**0.5)\n","\n","  return err, sum(err_abs)/len(err), max(err), min(err)\n","\n","def get_vect_err(s, m) :\n","  \"\"\" \n","  Inputs : simulated vector, modeled stress col\n","  Returns : vect error\n","  \"\"\"\n","  err = []\n","  err_abs = []\n","  for i in range(len(m)) :\n","      disp_s = s[i][0]\n","      disp_m = m[i][0]\n","      if disp_s != 0 :\n","          err.append((((disp_m - disp_s)/disp_s)))\n","          err_abs.append((((disp_m - disp_s)/disp_s)**2)**0.5)\n","      else :\n","          err.append((((disp_m - disp_s))))\n","          err_abs.append((((disp_m - disp_s))**2)**0.5)\n","\n","  return err, sum(err_abs)/len(err), max(err), min(err)\n","\n","\n","def make_all_runnable_in_session(*args):\n","  \"\"\"Apply make_runnable_in_session to an iterable of graphs.\"\"\"\n","  return [utils_tf.make_runnable_in_session(a) for a in args]\n","\n","\n","\n","def get_node_trajectories(rollout_array, batch_size, idx0, idx1):  # pylint: disable=redefined-outer-name\n","  return np.split(rollout_array[..., idx0:idx1], batch_size, axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AxmZqyMCGGqp"},"source":["# **Plots**"]},{"cell_type":"code","metadata":{"id":"rP3Zk13zGQGR"},"source":["from matplotlib import cm\n","from matplotlib import colors\n","\n","font = {'family' : 'DejaVu Sans',\n","        'weight' : 'bold',\n","        'size'   : 16}\n","\n","mpl.rc('font', **font)\n","\n","def get_colors(inp, colormap):\n","    vmin = np.min(inp)\n","    vmax = np.max(inp)\n","    norm = plt.Normalize(vmin, vmax)\n","    return norm, colormap(norm(inp))\n","\n","def plot_mesh(elem_type, annotations, alternate_title, bound_x, bound_y,\n","              mesh, bc, uur, elem_stress, plot_bc = True) :\n","  # Plot Mesh\n","  fig = plt.figure(1, figsize=(50, 10))\n","  ax = fig.add_subplot(1, 2, 1)\n","  plt.xticks((np.arange( bound_x[0], bound_x[1] + 2*mesh.d1, step=5 *mesh.d1)) )\n","  plt.yticks((np.arange( bound_y[0], bound_y[1] + 2*mesh.d2, step=2 *mesh.d2)) )\n","  # ax.grid(True, which = 'both')\n","  ax.set_title(\"Mesh: \" + alternate_title) \n","  ax.set_ylabel('y')\n","  ax.set_xlabel('x')\n","\n","  #nodes\n","  x, y = np.asarray(mesh.coords).T\n","  ax.scatter(x, y, c = 'red', zorder = 10)\n","  if annotations is True :\n","    for i in range(mesh.n_node) :\n","      ax.annotate(str(i), (x[int(i)], y[int(i)]), size = 8)\n","\n","  #elements\n","  for elem in mesh.elem_nodes :\n","    if elem_type == \"tri\" :\n","      elem_coords= [mesh.coords[elem[0]], mesh.coords[elem[1]], \n","                          mesh.coords[elem[2]], mesh.coords[elem[0]]]\n","    else :\n","      elem_coords= [mesh.coords[elem[0]], mesh.coords[elem[1]], \n","                          mesh.coords[elem[2]], mesh.coords[elem[3]], mesh.coords[elem[0]]]\n","    x, y = np.asarray(elem_coords).T\n","    ax.plot(x, y, 'k')\n","  if annotations is True :\n","    for elem in mesh.elem_nodes : \n","      x_bar = 0\n","      y_bar = 0\n","      for i in elem :\n","        x_bar += mesh.coords[i][0]\n","        y_bar += mesh.coords[i][1]\n","      if elem_type == \"tri\" :\n","        x, y = np.asarray([x_bar/3, y_bar/3]).T\n","      else :\n","        x, y = np.asarray([x_bar/4, y_bar/4]).T\n","      ax.annotate(mesh.elem_nodes.index(elem), (x, y), \n","                  size = 8, ha='center', va='bottom')\n","      \n","  #boundary conditions\n","  for i in bc.eq_num[0].tolist() :\n","    if i < 0 :\n","      node = (bc.eq_num[0].tolist().index(i))\n","      x, y = np.asarray(mesh.coords[node]).T\n","      ax.plot(x, y, '>k', markersize = 12, fillstyle = 'none', mew =2)\n","  for i in bc.eq_num[1].tolist() :\n","    if i < 0 :\n","      node = (bc.eq_num[1].tolist().index(i))\n","      x, y = np.asarray(mesh.coords[node]).T\n","      ax.plot(x, y, '^k', markersize = 12, fillstyle = 'none', mew =2)\n","  for i in bc.force_node :\n","    x, y = np.asarray(mesh.coords[i]).T\n","    ax.plot(x, y, 'or', markersize = 16, fillstyle = 'none', mew =2)\n","\n","\n","\n","  ################################################################################\n","  #Plot deformed condition \n","  norm, color_array = get_colors(elem_stress, plt.cm.jet)\n","  new_coords = uur.T + np.array(mesh.coords)\n","  ax = fig.add_subplot(1, 2, 2)\n","\n","  #Undeformed Nodes\n","  x, y = np.asarray(mesh.coords).T\n","  plt.xticks((np.arange( bound_x[0], bound_x[1] + 2*mesh.d1, step=5 *mesh.d1)) )\n","  plt.yticks((np.arange( bound_y[0], bound_y[1] + 2*mesh.d2, step=2 *mesh.d2)) )\n","  # ax.grid(True, which = 'both')\n","  ax.set_title(\"Deformed Mesh with Von Mises Stress\") \n","  ax.set_ylabel('y')\n","  ax.set_xlabel('x')\n","  ax.scatter(x, y, c = 'gray')\n","\n","  #Undeformed Elements\n","  for elem in mesh.elem_nodes :\n","    if elem_type == \"tri\" :\n","      elem_coords= [mesh.coords[elem[0]], mesh.coords[elem[1]], \n","                          mesh.coords[elem[2]], mesh.coords[elem[0]]]\n","    else :\n","      elem_coords= [mesh.coords[elem[0]], mesh.coords[elem[1]], \n","                          mesh.coords[elem[2]], mesh.coords[elem[3]], mesh.coords[elem[0]]]\n","    x, y = np.asarray(elem_coords).T\n","    ax.plot(x, y, 'gray', linewidth = 1)\n","\n","\n","  #Deformed Nodes\n","  x, y = (new_coords).T\n","  ax.scatter(x, y, c = 'black', zorder = 10)\n","\n","  #Deformed Elements\n","  for i, elem in enumerate(mesh.elem_nodes ): \n","    if elem_type == \"tri\" :\n","      elem_coords= [new_coords[elem[0]], new_coords[elem[1]], \n","                          new_coords[elem[2]], new_coords[elem[0]]]\n","    else :\n","      elem_coords= [new_coords[elem[0]], new_coords[elem[1]], \n","                          new_coords[elem[2]], new_coords[elem[3]], new_coords[elem[0]]]\n","    x, y = np.asarray(elem_coords).T\n","    ax.plot(x, y, 'red', linewidth = 3)\n","    if plot_bc :\n","      plt.fill_between(x, y, color = color_array[i])\n","\n","  cax, _ = mpl.colorbar.make_axes(ax) \n","  cb2 = mpl.colorbar.ColorbarBase(cax, cmap=plt.cm.jet,norm=norm) \n","  \n","  #Deformed Boundary Conditions\n","  if plot_bc :\n","    for i in bc.eq_num[0].tolist() :\n","      if i < 0 :\n","        node = (bc.eq_num[0].tolist().index(i))\n","        x, y = np.asarray(new_coords[node]).T\n","        ax.plot(x, y, '>k', markersize = 12, fillstyle = 'none', mew =2)\n","    for i in bc.eq_num[1].tolist() :\n","      if i < 0 :\n","        node = (bc.eq_num[1].tolist().index(i))\n","        x, y = np.asarray(new_coords[node]).T\n","        ax.plot(x, y, '^k', markersize = 12, fillstyle = 'none', mew =2)\n","    for i in bc.force_node :\n","      x, y = np.asarray(new_coords[i]).T\n","      ax.plot(x, y, 'or', markersize = 16, fillstyle = 'none', mew =2)\n","  plt.show()\n","  fig.clf()\n","\n","def plot_nodal_vect(x, y, z, title, size) :\n","  fig = plt.figure(1, figsize=(10, 5))\n","  # Plot Mesh\n","  ax = fig.add_subplot(1, 1, 1)\n","  ax.set_title(title) \n","  ax.set_ylabel('y')\n","  ax.set_xlabel('x')\n","  #nodes\n","  plt.scatter(x, y, c=z, marker = 's', s = size,\n","              cmap='jet',vmin= z.min(), vmax= z.max())\n","  plt.colorbar()\n","  plt.show()\n","  fig.clf()\n","\n","def plot_elem_attr(elem_type, title, mesh, elem_array) :\n","  \n","  fig = plt.figure(1, figsize=(50, 20))\n","  size = 1e3 * 1000 / mesh.n_node\n","  \n","  elem_coords = []\n","  if elem_type == \"tri\" :\n","    nodes_per_elem = 3\n","    z_plot = [elem_array.T[0, ...], elem_array.T[2, ...], elem_array.T[2, ...], elem_array.T[1, ...]]\n","  else :\n","    nodes_per_elem = 4\n","    z_plot = [elem_array.T[0, ...], elem_array.T[1, ...], elem_array.T[2, ...], elem_array.T[3, ...]]\n","  for elem in mesh.elem_nodes :\n","    avg_x = 0\n","    avg_y = 0\n","    for node in elem:\n","      avg_x += mesh.coords[node][0] / nodes_per_elem\n","      avg_y += mesh.coords[node][1] / nodes_per_elem\n","    elem_coords.append([avg_x, avg_y])\n","  \n","\n","  # 11\n","  z = z_plot[0]\n","  ax = fig.add_subplot(2, 2, 1)\n","  ax.set_title(title + \" 11\") \n","  ax.set_ylabel('y')\n","  ax.set_xlabel('x')\n","  #nodes\n","  x, y = np.asarray(elem_coords).T\n","  plt.scatter(x, y, c=z, marker = 's', s = size,\n","              cmap='jet',vmin=z.min(), vmax=z.max())\n","  plt.colorbar()\n","\n","  # 21\n","  z = z_plot[1]\n","  ax = fig.add_subplot(2, 2, 2)\n","  ax.set_title(title + \" 21\") \n","  ax.set_ylabel('y')\n","  ax.set_xlabel('x')\n","  #nodes\n","  x, y = np.asarray(elem_coords).T\n","  plt.scatter(x, y, c=z, marker = 's', s = size,\n","              cmap='jet',vmin=z.min(), vmax=z.max())\n","  plt.colorbar()\n","\n","  # 12\n","  z = z_plot[2]\n","  ax = fig.add_subplot(2, 2, 3)\n","  ax.set_title(title + \" 12\") \n","  ax.set_ylabel('y')\n","  ax.set_xlabel('x')\n","  #nodes\n","  x, y = np.asarray(elem_coords).T\n","  plt.scatter(x, y, c=z, marker = 's', s = size,\n","              cmap='jet',vmin=z.min(), vmax=z.max())\n","  plt.colorbar()\n","\n","  # 22\n","  z = z_plot[3]\n","  ax = fig.add_subplot(2, 2, 4)\n","  ax.set_title(title + \" 22\") \n","  ax.set_ylabel('y')\n","  ax.set_xlabel('x')\n","  #nodes\n","  x, y = np.asarray(elem_coords).T\n","  plt.scatter(x, y, c=z, marker = 's', s = size,\n","              cmap='jet',vmin=z.min(), vmax=z.max())\n","  plt.colorbar()\n","  plt.show()\n","  fig.clf()\n","\n","def plot_capped_nodal_vect(x, y, z, title, size, cap_min, cap_max) :\n","  fig = plt.figure(1, figsize=(50, 10))\n","  # Plot Mesh\n","  delta = 0.1\n","  ax = fig.add_subplot(1, 2, 1)\n","  ax.set_title(title) \n","  ax.set_ylabel('y')\n","  ax.set_xlabel('x')\n","  ax.set_xlim(x.min() - delta, x.max() + delta)\n","  ax.set_ylim(y.min() - delta, y.max() + delta)\n","  #nodes\n","  plt.scatter(x, y, c=z, marker = 's', s = size,\n","              cmap='jet',vmin= cap_min, vmax= cap_max)\n","  plt.colorbar()\n","  plt.show()\n","  fig.clf()"],"execution_count":null,"outputs":[]}]}